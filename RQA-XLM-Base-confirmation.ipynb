{"metadata":{"colab":{"name":"Question Answering on SQUAD","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8604663,"sourceType":"datasetVersion","datasetId":5148683}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"If you're opening this Notebook on colab, you will probably need to install ЁЯдЧ Transformers and ЁЯдЧ Datasets. Uncomment the following cell and run it.","metadata":{"id":"X4cRE8IbIrIV"}},{"cell_type":"code","source":"! pip install datasets transformers","metadata":{"id":"MOsHUjgdIrIW","execution":{"iopub.status.busy":"2024-06-12T15:27:52.159363Z","iopub.execute_input":"2024-06-12T15:27:52.160149Z","iopub.status.idle":"2024-06-12T15:28:07.015377Z","shell.execute_reply.started":"2024-06-12T15:27:52.160083Z","shell.execute_reply":"2024-06-12T15:28:07.014163Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.19.2)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.41.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (14.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.1)\nRequirement already satisfied: requests>=2.32.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.1->datasets) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"If you're opening this notebook locally, make sure your environment has an install from the last version of those libraries.\n\nTo be able to share your model with the community and generate results like the one shown in the picture below via the inference API, there are a few more steps to follow.\n\nFirst you have to store your authentication token from the Hugging Face website (sign up [here](https://huggingface.co/join) if you haven't already!) then execute the following cell and input your username and password:","metadata":{"id":"jQOXdW11w2Dw"}},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"id":"ibkuaKivw2Dw","execution":{"iopub.status.busy":"2024-06-12T15:28:07.017651Z","iopub.execute_input":"2024-06-12T15:28:07.018498Z","iopub.status.idle":"2024-06-12T15:28:07.328703Z","shell.execute_reply.started":"2024-06-12T15:28:07.018458Z","shell.execute_reply":"2024-06-12T15:28:07.327852Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svтАж","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c815424f60e4efb89ce16952d3d1255"}},"metadata":{}}]},{"cell_type":"markdown","source":"Then you need to install Git-LFS. Uncomment the following instructions:","metadata":{"id":"U_F5xs7Pw2Dw"}},{"cell_type":"code","source":"# !apt install git-lfs","metadata":{"id":"nz4DbvRJw2Dx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Make sure your version of Transformers is at least 4.11.0 since the functionality was introduced in that version:","metadata":{"id":"6FjQUFZmw2Dx"}},{"cell_type":"code","source":"import transformers\n\nprint(transformers.__version__)","metadata":{"id":"aODkpq0tw2Dx","execution":{"iopub.status.busy":"2024-06-12T15:28:21.058831Z","iopub.execute_input":"2024-06-12T15:28:21.059254Z","iopub.status.idle":"2024-06-12T15:28:24.706072Z","shell.execute_reply.started":"2024-06-12T15:28:21.059219Z","shell.execute_reply":"2024-06-12T15:28:24.705147Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"4.41.2\n","output_type":"stream"}]},{"cell_type":"markdown","source":"You can find a script version of this notebook to fine-tune your model in a distributed fashion using multiple GPUs or TPUs [here](https://github.com/huggingface/transformers/tree/master/examples/question-answering).","metadata":{"id":"HFASsisvIrIb"}},{"cell_type":"markdown","source":"We also quickly upload some telemetry - this tells us which examples and software versions are getting used so we know where to prioritize our maintenance efforts. We don't collect (or care about) any personally identifiable information, but if you'd prefer not to be counted, feel free to skip this step or delete this cell entirely.","metadata":{"id":"oRZRpmstw2Dy"}},{"cell_type":"code","source":"from transformers.utils import send_example_telemetry\n\nsend_example_telemetry(\"question_answering_notebook\", framework=\"pytorch\")","metadata":{"id":"tGmq-cTbw2Dy","execution":{"iopub.status.busy":"2024-06-12T15:28:24.707745Z","iopub.execute_input":"2024-06-12T15:28:24.708167Z","iopub.status.idle":"2024-06-12T15:28:24.714978Z","shell.execute_reply.started":"2024-06-12T15:28:24.708139Z","shell.execute_reply":"2024-06-12T15:28:24.713857Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Fine-tuning a model on a question-answering task","metadata":{"id":"rEJBSTyZIrIb"}},{"cell_type":"markdown","source":"In this notebook, we will see how to fine-tune one of the [ЁЯдЧ Transformers](https://github.com/huggingface/transformers) model to a question answering task, which is the task of extracting the answer to a question from a given context. We will see how to easily load a dataset for these kinds of tasks and use the `Trainer` API to fine-tune a model on it.\n\n![Widget inference representing the QA task](https://github.com/huggingface/notebooks/blob/master/examples/images/question_answering.png?raw=1)\n\n**Note:** This notebook finetunes models that answer question by taking a substring of a context, not by generating new text.","metadata":{"id":"McEmFvdvw2Dy"}},{"cell_type":"markdown","source":"This notebook is built to run on any question answering task with the same format as SQUAD (version 1 or 2), with any model checkpoint from the [Model Hub](https://huggingface.co/models) as long as that model has a version with a token classification head and a fast tokenizer (check on [this table](https://huggingface.co/transformers/index.html#bigtable) if this is the case). It might just need some small adjustments if you decide to use a different dataset than the one used here. Depending on you model and the GPU you are using, you might need to adjust the batch size to avoid out-of-memory errors. Set those three parameters, then the rest of the notebook should run smoothly:","metadata":{"id":"4RRkXuteIrIh"}},{"cell_type":"code","source":"# This flag is the difference between SQUAD v1 or 2 (if you're using another dataset, it indicates if impossible\n# answers are allowed or not).\nsquad_v2 = False\nmodel_checkpoint = \"FacebookAI/xlm-roberta-base\"\nbatch_size = 16","metadata":{"id":"zVvslsfMIrIh","execution":{"iopub.status.busy":"2024-06-12T15:28:25.771886Z","iopub.execute_input":"2024-06-12T15:28:25.772260Z","iopub.status.idle":"2024-06-12T15:28:25.776675Z","shell.execute_reply.started":"2024-06-12T15:28:25.772230Z","shell.execute_reply":"2024-06-12T15:28:25.775760Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Loading the dataset","metadata":{"id":"whPRbBNbIrIl"}},{"cell_type":"markdown","source":"We will use the [ЁЯдЧ Datasets](https://github.com/huggingface/datasets) library to download the data and get the metric we need to use for evaluation (to compare our model to the benchmark). This can be easily done with the functions `load_dataset` and `load_metric`.  ","metadata":{"id":"W7QYTpxXIrIl"}},{"cell_type":"markdown","source":"For our example here, we'll use the [SQUAD dataset](https://rajpurkar.github.io/SQuAD-explorer/). The notebook should work with any question answering dataset provided by the ЁЯдЧ Datasets library. If you're using your own dataset defined from a JSON or csv file (see the [Datasets documentation](https://huggingface.co/docs/datasets/loading_datasets.html#from-local-files) on how to load them), it might need some adjustments in the names of the columns used.","metadata":{"id":"CKx2zKs5IrIq"}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndatasets = load_dataset(\"shakun42/BanglaRQA_to_SquadBn_fact_confirm\")","metadata":{"id":"s_AY1ATSIrIq","outputId":"fd0578d1-8895-443d-b56f-5908de9f1b6b","execution":{"iopub.status.busy":"2024-06-12T15:28:28.006353Z","iopub.execute_input":"2024-06-12T15:28:28.007226Z","iopub.status.idle":"2024-06-12T15:28:32.083257Z","shell.execute_reply.started":"2024-06-12T15:28:28.007191Z","shell.execute_reply":"2024-06-12T15:28:32.082508Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/714 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d066d5bacdd42ca9c9ad0f6d04b1fea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/6.21M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87f222c5f485484eb4f22d9f8e8ea130"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/803k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb84569c81fc472c8488bab20ef15315"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/752k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f05660c55e64fbdbd02b67946f48869"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/9565 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecb0f5235fe44c78ab6e8b0bd131677e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1182 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29765dcf3deb44fca8f31f9bf20abe4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1172 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f4b8ba35b264e6cbde2c2150a0d367d"}},"metadata":{}}]},{"cell_type":"markdown","source":"The `datasets` object itself is [`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict), which contains one key for the training, validation and test set.","metadata":{"id":"RzfPtOMoIrIu"}},{"cell_type":"code","source":"datasets","metadata":{"id":"GWiVUF0jIrIv","outputId":"35e3ea43-f397-4a54-c90c-f2cf8d36873e","execution":{"iopub.status.busy":"2024-06-12T15:28:33.569994Z","iopub.execute_input":"2024-06-12T15:28:33.570973Z","iopub.status.idle":"2024-06-12T15:28:33.579055Z","shell.execute_reply.started":"2024-06-12T15:28:33.570934Z","shell.execute_reply":"2024-06-12T15:28:33.578159Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 9565\n    })\n    validation: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 1182\n    })\n    test: Dataset({\n        features: ['id', 'title', 'context', 'question', 'answers'],\n        num_rows: 1172\n    })\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"We can see the training, validation and test sets all have a column for the context, the question and the answers to those questions.","metadata":{"id":"MYCQycO0w2D0"}},{"cell_type":"markdown","source":"To access an actual element, you need to select a split first, then give an index:","metadata":{"id":"u3EtYfeHIrIz"}},{"cell_type":"code","source":"datasets[\"train\"][0]","metadata":{"id":"X6HrpprwIrIz","outputId":"d7670bc0-42e4-4c09-8a6a-5c018ded7d95","execution":{"iopub.status.busy":"2024-06-12T15:28:35.497065Z","iopub.execute_input":"2024-06-12T15:28:35.497802Z","iopub.status.idle":"2024-06-12T15:28:35.507430Z","shell.execute_reply.started":"2024-06-12T15:28:35.497767Z","shell.execute_reply":"2024-06-12T15:28:35.506389Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'id': 'bn_wiki_2977_03',\n 'title': 'ржлрж╛ржЬрж┐рж▓ ржкрж░рзАржХрзНрж╖рж╛',\n 'context': 'ржлрж╛ржЬрж┐рж▓ ржкрж░рзАржХрзНрж╖рж╛ ржмрж╛ржВрж▓рж╛ржжрзЗрж╢ ржУ ржнрж╛рж░рждрзЗрж░ ржЖрж▓рж┐ржпрж╝рж╛ ржорж╛ржжрзНрж░рж╛рж╕рж╛ржпрж╝ ржЕржирзБрж╖рзНржарж┐ржд ржПржХржЯрж┐ рж╕рж░ржХрж╛рж░рж┐ ржкрж░рзАржХрзНрж╖рж╛ред ржлрж╛ржЬрж┐рж▓ ржкрж░рзАржХрзНрж╖рж╛ ржмрж╛ржВрж▓рж╛ржжрзЗрж╢рзЗ ржбрж┐ржЧрзНрж░рж┐ рж╕ржоржорж╛ржирзЗрж░, ржХржЦржирзЛ рж╕рзНржирж╛рждржХ рж╕ржоржорж╛ржирзЗрж░ ржПржХржЯрж┐ ржкрж░рзАржХрзНрж╖рж╛, ржпрж╛ ржПржХржЯрж┐ ржлрж╛ржЬрж┐рж▓ ржорж╛ржжрзНрж░рж╛рж╕рж╛ржпрж╝ ржЕржирзБрж╖рзНржарж┐ржд рж╣ржпрж╝рзЗ ржерж╛ржХрзЗред рждржмрзЗ ржнрж╛рж░рждрзЗ ржлрж╛ржЬрж┐рж▓ ржкрж░рзАржХрзНрж╖рж╛ржХрзЗ ржЙржЪрзНржЪ ржорж╛ржзрзНржпржорж┐ржХ рж╢рзНрж░рзЗржгрзАрж░ (рззрзз ржмрж╛ рззрзи ржХрзНрж▓рж╛рж╕) ржорж╛ржи ржмрж▓рзЗ ржмрж┐ржмрзЗржЪрж┐ржд ржХрж░рж╛ рж╣ржпрж╝ред ржлрж╛ржЬрж┐рж▓ ржкрж░рзАржХрзНрж╖рж╛ ржмрж╛ржВрж▓рж╛ржжрзЗрж╢ ржнрж╛рж░ржд ржУ ржкрж╛ржХрж┐рж╕рзНрждрж╛ржирзЗрж░ рж╕рж░ржХрж╛рж░рж┐ рж╕рзНржмрзАржХрзГржд ржЖрж▓рж┐ржпрж╝рж╛ ржорж╛ржжрж░рж╛рж╕рж╛ржпрж╝ ржкрзНрж░ржЪрж▓рж┐ржд рж░ржпрж╝рзЗржЫрзЗред ржмрж╛ржВрж▓рж╛ржжрзЗрж╢рзЗрж░ ржлрж╛ржЬрж┐рж▓ ржкрж░рзАржХрзНрж╖рж╛ ржЗрж╕рж▓рж╛ржорж┐ ржЖрж░ржмрж┐ ржмрж┐рж╢рзНржмржмрж┐ржжрзНржпрж╛рж▓ржпрж╝рзЗрж░ ржЕржзрзАржирзЗ ржЕржирзБрж╖рзНржарж┐ржд рж╣ржпрж╝рзЗ ржерж╛ржХрзЗ ржУ ржнрж╛рж░рждрзЗрж░ ржлрж╛ржЬрж┐рж▓ ржкрж░рзАржХрзНрж╖рж╛ ржкрж╢рзНржЪрж┐ржоржмржЩрзНржЧ ржорж╛ржжрзНрж░рж╛рж╕рж╛ рж╢рж┐ржХрзНрж╖рж╛ ржкрж░рзНрж╖ржжрзЗрж░ ржЕржзрзАржирзЗ ржЕржирзБрж╖рзНржарж┐ржд рж╣ржпрж╝рзЗ ржерж╛ржХрзЗред\\n\\nрззрзпрзкрзн рж╕рж╛рж▓рзЗ ржврж╛ржХрж╛ ржЖрж▓рж┐ржпрж╝рж╛ ржорж╛ржжрзНрж░рж╛рж╕рж╛ ржврж╛ржХрж╛ржпрж╝ рж╕рзНржерж╛ржирж╛ржирзНрждрж░рзЗрж░ ржкрзВрж░рзНржмрзЗ ржмрж╛ржВрж▓рж╛ржжрзЗрж╢ ржУ ржнрж╛рж░рждрзЗрж░ ржлрж╛ржЬрж┐рж▓ ржкрж░рзАржХрзНрж╖рж╛ ржХрж▓ржХрж╛рждрж╛ ржЖрж▓рж┐ржпрж╝рж╛ ржорж╛ржжрзНрж░рж╛рж╕рж╛рж░ ржЕржзрзАржирзЗ ржЕржирзБрж╖рзНржарж┐ржд рж╣рждрзЛред ржлрж╛ржпрж┐рж▓ ржкрж░рзАржХрзНрж╖рж╛ ржмрж░рзНрждржорж╛ржирзЗ ржЗрж╕рж▓рж╛ржорж┐ ржЖрж░ржмрзА ржмрж┐рж╢рзНржмржмрж┐ржжрзНржпрж╛рж▓ржпрж╝рзЗрж░ ржЕржзрзАржирзЗ ржЕржирзБрж╖рзНржарж┐ржд рж╣ржпрж╝ред ржпрж╛ ржкрзВрж░рзНржмрзЗ ржорж╛ржжрж░рж╛рж╕рж╛ ржмрзЛрж░рзНржб ржУ ржЗрж╕рж▓рж╛ржорж┐ ржмрж┐рж╢рзНржмржмрж┐ржжрзНржпрж╛рж▓ржпрж╝рзЗрж░ ржЖржзрзАржирзЗ ржЕржирзБрж╖рзНржарж┐ржд рж╣рждред ржорж╛ржжрзНрж░рж╛рж╕рж╛-ржЗ-ржЖрж▓рж┐ржпрж╝рж╛ ржврж╛ржХрж╛ржпрж╝ рж╕рзНржерж╛ржирж╛ржирзНрждрж░рж┐ржд рж╣рж▓рзЗ рззрзпрзкрзо рж╕рж╛рж▓рзЗ ржорж╛ржжрзНрж░рж╛рж╕рж╛ ржмрзЛрж░рзНржбрзЗрж░ ржлрж╛ржЬрж┐рж▓ржЧрзБрж▓рзЛ ржкрж░рзАржХрзНрж╖рж╛ ржврж╛ржХрж╛ ржмрж┐рж╢рзНржмржмрж┐ржжрзНржпрж╛рж▓ржпрж╝ ржХрж░рзНрждрзГржХ ржЧрзГрж╣рзАржд рж╣рждрзЛред рззрзпрзнрзл рж╕рж╛рж▓рзЗрж░ ржХрзБржжрж░ржд-ржП-ржЦрзБржжрж╛ рж╢рж┐ржХрзНрж╖рж╛ ржХржорж┐рж╢ржирзЗрж░ рж╕рзБржкрж╛рж░рж┐рж╢рзЗ ржорж╛ржжрзНрж░рж╛рж╕рж╛ ржмрзЛрж░рзНржб ржирж┐ржпрж╝ржирзНрждрзНрж░рж┐ржд ржЖрж▓рж┐ржпрж╝рж╛ ржорж╛ржжрзНрж░рж╛рж╕рж╛рж╕ржорзВрж╣рзЗ ржЬрж╛рждрзАржпрж╝ рж╢рж┐ржХрзНрж╖рж╛ржХрзНрж░ржо ржУ ржмрж╣рзБржорзБржЦрзА ржкрж╛ржарзНржпрж╕рзВржЪрж┐ ржкрзНрж░ржмрж░рзНрждрж┐ржд ржХрж░рж╛ рж╣ржпрж╝ред рззрзпрзорзж рж╕рж╛рж▓рзЗ ржЕржирзБрж╖рзНржарж┐ржд ржлрж╛ржЬрж┐рж▓ ржкрж░рзАржХрзНрж╖рж╛ржпрж╝ ржПржЗ ржкрж╛ржарзНржпрж╕рзБржЪрзА ржХрж╛рж░рзНржпржХрж░ рж╣ржпрж╝ред ржПржЗ рж╢рж┐ржХрзНрж╖рж╛ ржХржорж┐рж╢ржи ржЕржирзБрж╕рж╛рж░рзЗ ржлрж╛ржЬрж┐рж▓ рж╢рзНрж░рзЗржгрзАрждрзЗ ржЗрж╕рж▓рж╛ржорж┐ рж╢рж┐ржХрзНрж╖рж╛рж░ ржкрж╛рж╢рж╛ржкрж╛рж╢рж┐ рж╕рж╛ржзрж╛рж░ржг ржкрж╛ржарзНржпрж╕рзВржЪрзА ржЕржирзНрждрж░рзНржнрзБржХрзНржд ржХрж░рзЗ ржлрж╛ржЬрж┐рж▓ ржкрж░рзАржХрзНрж╖рж╛ржХрзЗ рж╕рж╛ржзрж╛рж░ржг ржЙржЪрзНржЪ ржорж╛ржзрзНржпржорж┐ржХ ржПржЗржЪ ржПрж╕ рж╕рж┐рж░ рж╕ржоржорж╛ржи ржШрзЛрж╖ржгрж╛ ржХрж░рж╛ рж╣ржпрж╝ред\\n\\nрззрзпрзнрзо рж╕рж╛рж▓рзЗ ржЕржзрзНржпрж╛ржкржХ ржорзБрж╕рзНрждржлрж╛ ржмрж┐ржи ржХрж╛рж╕рж┐ржорзЗрж░ ржирзЗрждрзГрждрзНржмрзЗ рж╕рж┐ржирж┐ржпрж╝рж░ ржорж╛ржжрзНрж░рж╛рж╕рж╛ рж╢рж┐ржХрзНрж╖рж╛ ржмрзНржпржмрж╕рзНржерж╛ ржХржорж┐ржЯрж┐ ржЧржарж┐ржд рж╣ржпрж╝ред ржПржЗ ржХржорж┐ржЯрж┐рж░ ржирж┐рж░рзНржжрзЗрж╢ржирж╛ржпрж╝ рззрзпрзорзк рж╕рж╛рж▓рзЗ рж╕рж╛ржзрж╛рж░ржг рж╢рж┐ржХрзНрж╖рж╛рж░ рж╕рзНрждрж░рзЗрж░ рж╕ржЩрзНржЧрзЗ ржмрж╛ржВрж▓рж╛ржжрзЗрж╢ ржорж╛ржжрзНрж░рж╛рж╕рж╛ ржмрзЛрж░рзНржб ржирж┐ржпрж╝ржирзНрждрзНрж░рж┐ржд ржЖрж▓рж┐ржпрж╝рж╛ ржорж╛ржжрзНрж░рж╛рж╕рж╛ рж╢рж┐ржХрзНрж╖рж╛ рж╕рзНрждрж░рзЗрж░ рж╕рж╛ржоржЮрзНржЬрж╕рзНржп ржХрж░рж╛ рж╣ржпрж╝ред ржлрж╛ржЬрж┐рж▓ рж╕рзНрждрж░ржХрзЗ рзи ржмржЫрж░ ржорзЗржпрж╝рж╛ржжрзА ржХрзЛрж░рзНрж╕рзЗ ржЙржирзНржирж┐ржд ржХрж░рзЗ, ржорзЛржЯ рззрзм ржмржЫрж░ ржмрзНржпрж╛ржкрзА ржЖрж▓рж┐ржпрж╝рж╛ ржорж╛ржжрзНрж░рж╛рж╕рж╛рж░ ржкрзВрж░рзНржгрж╛ржЩрзНржЧ ржЖржзрзБржирж┐ржХ рж╢рж┐ржХрзНрж╖рж╛ ржмрзНржпржмрж╕рзНржерж╛ ржкрзНрж░ржмрж░рзНрждржи ржХрж░рж╛ рж╣ржпрж╝ред ржПржЗ ржХржорж┐рж╢ржирзЗрж░ ржорж╛ржзрзНржпржорзЗржЗ рж╕рж░ржХрж╛рж░ ржлрж╛ржЬрж┐рж▓ ржкрж░рзАржХрзНрж╖рж╛ржХрзЗ рж╕рж╛ржзрж╛рж░ржг ржбрж┐ржЧрзНрж░рж┐ ржорж╛ржи ржШрзЛрж╖ржгрж╛ ржХрж░рзЗред',\n 'question': 'ржХржд рж╕рж╛рж▓рзЗ ржврж╛ржХрж╛ ржЖрж▓рж┐ржпрж╝рж╛ ржорж╛ржжрзНрж░рж╛рж╕рж╛ ржврж╛ржХрж╛ржпрж╝ рж╕рзНржерж╛ржирж╛ржирзНрждрж░рзЗрж░ ржкрзВрж░рзНржмрзЗ ржмрж╛ржВрж▓рж╛ржжрзЗрж╢ ржУ ржнрж╛рж░рждрзЗрж░ ржлрж╛ржЬрж┐рж▓ ржкрж░рзАржХрзНрж╖рж╛ ржХрж▓ржХрж╛рждрж╛ ржЖрж▓рж┐ржпрж╝рж╛ ржорж╛ржжрзНрж░рж╛рж╕рж╛рж░ ржЕржзрзАржирзЗ ржЕржирзБрж╖рзНржарж┐ржд рж╣рждрзЛ ?',\n 'answers': {'answer_start': [543, 543], 'text': ['рззрзпрзкрзн', 'рззрзпрзкрзн']}}"},"metadata":{}}]},{"cell_type":"markdown","source":"We can see the answers are indicated by their start position in the text (here at character 515) and their full text, which is a substring of the context as we mentioned above.","metadata":{"id":"A78GGG71w2D0"}},{"cell_type":"markdown","source":"To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset (automatically decoding the labels in passing).","metadata":{"id":"WHUmphG3IrI3"}},{"cell_type":"code","source":"from datasets import ClassLabel, Sequence\nimport random\nimport pandas as pd\nfrom IPython.display import display, HTML\n\ndef show_random_elements(dataset, num_examples=10):\n    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n    picks = []\n    for _ in range(num_examples):\n        pick = random.randint(0, len(dataset)-1)\n        while pick in picks:\n            pick = random.randint(0, len(dataset)-1)\n        picks.append(pick)\n\n    df = pd.DataFrame(dataset[picks])\n    for column, typ in dataset.features.items():\n        if isinstance(typ, ClassLabel):\n            df[column] = df[column].transform(lambda i: typ.names[i])\n        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n    display(HTML(df.to_html()))","metadata":{"id":"i3j8APAoIrI3","execution":{"iopub.status.busy":"2024-06-12T15:28:37.208374Z","iopub.execute_input":"2024-06-12T15:28:37.208741Z","iopub.status.idle":"2024-06-12T15:28:37.218573Z","shell.execute_reply.started":"2024-06-12T15:28:37.208712Z","shell.execute_reply":"2024-06-12T15:28:37.217564Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"show_random_elements(datasets[\"train\"])","metadata":{"id":"SZy5tRB_IrI7","outputId":"ba8f2124-e485-488f-8c0c-254f34f24f13","scrolled":true,"execution":{"iopub.status.busy":"2024-06-12T15:28:38.405667Z","iopub.execute_input":"2024-06-12T15:28:38.406532Z","iopub.status.idle":"2024-06-12T15:28:38.435110Z","shell.execute_reply.started":"2024-06-12T15:28:38.406497Z","shell.execute_reply":"2024-06-12T15:28:38.434074Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>title</th>\n      <th>context</th>\n      <th>question</th>\n      <th>answers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>bn_wiki_1569_05</td>\n      <td>ржкрж╛ржмрж▓рзЛ ржирзЗрж░рзБржжрж╛</td>\n      <td>ржЪрж┐рж▓рж┐рждрзЗ ржлрзЗрж░рж╛рж░ ржкрж░ ржирзЗрж░рзБржжрж╛ржХрзЗ ржмрзБржпрж╝рзЗржирзЛрж╕ ржЖржЗрж░рзЗрж╕рзЗ ржХрзВржЯржирзИрждрж┐ржХ ржкржж ржжрзЗржУржпрж╝рж╛ рж╣ржпрж╝рзЗржЫрж┐рж▓, ржПржмржВ ржкрж░рзЗ рж╕рзНржкрзЗржирзЗрж░ ржмрж╛рж░рзНрж╕рзЗрж▓рзЛржирж╛ржпрж╝ ржкрж╛ржарж╛ржирзЛ рж╣ржпрж╝ред ржкрж░ржмрж░рзНрждрзАржХрж╛рж▓рзЗ рждрж┐ржирж┐ ржорж╛ржжрзНрж░рж┐ржжрзЗ ржХржирж╕рзБрж▓ рж╣рж┐рж╕рзЗржмрзЗ ржЧрзНржпрж╛ржмрзНрж░рж┐ржпрж╝рзЗрж▓рж╛ ржорж┐рж╕рзНрждрзНрж░рж╛рж▓рзЗрж░ рж╕рзНржерж▓рж╛ржнрж┐рж╖рж┐ржХрзНржд рж╣ржиред рж╕рзЗржЦрж╛ржирзЗ рждрж╛ржХрзЗ ржШрж┐рж░рзЗ ржПржХржЯрж┐ ржкрзНрж░рж╛ржгрзЛржЪрзНржЫрж▓ рж╕рж╛рж╣рж┐рждрзНржп ржорж╣рж▓ рждрзИрж░рж┐ рж╣ржпрж╝ ржПржмржВ рж▓рзЗржЦржХ рж░рж╛ржлрж╛ржпрж╝рзЗрж▓ ржЖрж▓ржмрзЗрж░рзНрждрж┐, ржлрзЗржжрзЗрж░рж┐ржХрзЛ ржЧрж╛рж░рж╕рж┐ржпрж╝рж╛ рж▓рзЛрж░ржХрж╛ ржУ ржкрзЗрж░рзБржнрзАржпрж╝ ржХржмрж┐ рж╕рзЗрж╕рж╛рж░ ржнрж╛ржЗржпрж╝рзЗрж╣рзЛрж░ рж╕рж╛ржерзЗ рждрж╛рж░ ржмржирзНржзрзБрждрзНржм рж╣ржпрж╝ред рждрж╛рж░ ржПржХржорж╛рждрзНрж░ ржХржирзНржпрж╛ ржорж╛рж▓ржнрж╛ ржорж╛рж░рж┐ржирж╛ (рждрзНрж░рж┐ржирж┐ржжрж╛ржж) рж░рзЗржЗржпрж╝рзЗрж╕ рззрзпрзйрзк рж╕рж╛рж▓рзЗ ржорж╛ржжрзНрж░рж┐ржжрзЗ ржЬржирзНржоржЧрзНрж░рж╣ржг ржХрж░рзЗржиред ржЫрзЛржЯржХрж╛рж▓ ржерзЗржХрзЗржЗ рждрж┐ржирж┐ рж░рзЛржЧржмрзНржпрж╛ржзрж┐рждрзЗ ржЬрж░рзНржЬрж░рж┐ржд ржЫрж┐рж▓рзЗржи, ржмрж┐рж╢рзЗрж╖ ржХрж░рзЗ рж╣рж╛ржЗржбрзНрж░рзЛрж╕рзЗржлрж╛рж▓рж╛рж╕рзЗ ржЖржХрзНрж░рж╛ржирзНржд ржЫрж┐рж▓рзЗржиред рждрж┐ржирж┐ рззрзпрзкрзй рж╕рж╛рж▓рзЗ ржорж╛рждрзНрж░ ржиржпрж╝ ржмржЫрж░рзЗ ржорж╛рж░рж╛ ржпрж╛ржиред ржорж╛рж▓ржнрж╛ рждрж╛рж░ ржПржЗ ржЫрзЛржЯрзНржЯ ржЬрзАржмржирзЗрж░ ржмрзЗрж╢рж┐рж░ржнрж╛ржЧ рж╕ржоржпрж╝ ржирзЗржжрж╛рж░рж▓рзНржпрж╛ржирзНржбрж╕рзЗ ржХрж╛ржЯрж╛ржи, ржХрж╛рж░ржг ржирзЗрж░рзБржжрж╛рж░ рждрж╛ржХрзЗ ржЙржкрзЗржХрзНрж╖рж╛ ржУ ржкрж░рж┐рждрзНржпрж╛ржЧ ржХрж░рж╛ржпрж╝ рждрж╛рж░ ржорж╛рждрж╛ рждрж╛ржжрзЗрж░ ржнрж░ржгржкрзЛрж╖ржгрзЗрж░ ржЬржирзНржп ржпрзЗ ржХрзЛржи ржзрж░ржирзЗрж░ ржХрж╛ржЬ ржирж┐рждрзЗ ржмрж╛ржзрзНржп рж╣ржпрж╝ред ржПржЗ рж╕ржоржпрж╝рзЗ ржирзЗрж░рзБржжрж╛ рждрж╛рж░ рж╕рзНрждрзНрж░рзАрж░ ржерзЗржХрзЗ ржмрж┐ржЪрзНржЫрж┐ржирзНржи рж╣рждрзЗ ржерж╛ржХрзЗржи ржПржмржВ рждрж╛рж░ ржЪрзЗржпрж╝рзЗ рзирзж ржмржЫрж░рзЗрж░ ржмржбрж╝ ржЕржнрж┐ржЬрж╛ржд ржЖрж░рзНржЬрзЗржирзНржЯрж┐ржирзАржпрж╝ рж╢рж┐рж▓рзНржкрзА ржжрзЗрж▓рж┐ржпрж╝рж╛ ржжрзЗрж▓ ржХрж╛рж░рж┐рж▓рзЗрж░ рж╕рж╛ржерзЗ рж╕ржорзНржкрж░рзНржХрзЗ ржЬржбрж╝рж╛ржиред</td>\n      <td>ржирзЗрж░рзБржжрж╛ ржХржд рж╕рж╛рж▓рзЗ ржирзЛржмрзЗрж▓ ржкрзБрж░рж╕рзНржХрж╛рж░ ржЕрж░рзНржЬржи ржХрж░рзЗржи?</td>\n      <td>{'answer_start': [], 'text': []}</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>bn_wiki_2212_02</td>\n      <td>рж╕рзНржЯрж╛рж░ ржУржпрж╝рж╛рж░рзНрж╕: ржжрзНржп ржлрзЛрж░рзНрж╕ ржЕрзНржпрж╛ржУржпрж╝рзЗржХрзЗржирзНрж╕</td>\n      <td>ржЧрзНржпрж╛рж▓рж╛ржХрзНржЯрж┐ржХ ржЧрзГрж╣ржпрзБржжрзНржзрзЗрж░ рзйрзж ржмржЫрж░ ржкрж░ ржЧрзНржпрж╛рж▓рж╛ржХрзНржЯрж┐ржХ рж╕ржорзНрж░рж╛ржЬрзНржпрзЗрж░ ржЙрждрзНрждрж░рж╕рзБрж░рзА 'ржлрж╛рж░рзНрж╕рзНржЯ ржЕрж░рзНржбрж╛рж░', ржирж┐ржЙ рж░рж┐ржкрж╛ржмрж▓рж┐ржХржХрзЗ ржХрзНрж╖ржорждрж╛ ржерзЗржХрзЗ ржЕржкрж╕рж╛рж░ржи ржХрж░рзЗ ржирж┐ржЬрзЗржжрзЗрж░ржХрзЗ ржЧрзНржпрж╛рж▓рж╛ржХрзНрж╕рж┐рж░ ржХрзНрж╖ржорждрж╛ржпрж╝ ржЕржзрж┐рж╕рзНржЯрж┐ржд ржХрж░рждрзЗ ржЪрж╛ржпрж╝ред\\n\\nржирж┐ржЙ рж░рж┐ржкрж╛ржмрж▓рж┐ржХ ржорзБржЦрж┐ рж╕рж╛ржорж░рж┐ржХ рж╕ржВрж╕рзНржерж╛ 'рж░рзЗрж╕рж┐рж╕рзНржЯрзЗржирзНрж╕' ржПрж░ ржкрзНрж░ржзрж╛ржи ржЬрзЗржирж╛рж░рзЗрж▓ рж▓рзЗржпрж╝рж╛ ржЕрж░ржЧрж╛ржирж╛ рждрж╛рж░ ржмрж┐рж╢рзНржмрж╕рзНржд ржХрж░рзНржоржЪрж╛рж░рзА ржХрзНржпрж╛ржкрзНржЯрзЗржи ржкрзЛ ржбрзНржпрж╛ржорзЗрж░ржи ржХрзЗ 'ржЬрж╛ржХрзНржХрзБ ' ржирж╛ржоржХ ржЧрзНрж░рж╣рзЗ ржкрж╛ржарж╛ржи ржПржХржЯрж┐ ржорзНржпрж╛ржк рж╕ржВржЧрзНрж░рж╣ ржХрж░рж╛рж░ ржЬржирзНржп, ржпрзЗржЦрж╛ржирзЗ рж▓рзЗржпрж╝рж╛рж░ ржнрж╛ржЗ ржЬрзЗржбрж╛ржЗ ржорж╛рж╕рзНржЯрж╛рж░ рж▓рзБржХ рж╕рзНржХрж╛ржЗржУржпрж╝рж╛ржХрж╛рж░рзЗрж░ ржарж┐ржХрж╛ржирж╛ ржЙрж▓рзНрж▓рзЗржЦ ржЖржЫрзЗред ржХрж┐ржирзНрждрзБ ржжрзБрж░ржнрж╛ржЧрзНржп ржмрж╢ржд ржкрзЛ рж░рзЗрж╕рж┐рж╕рзНржЯрзЗржирзНрж╕рзЗрж░ рж╢рждрзНрж░рзБ, ржлрж╛рж╕рзНржЯ ржЕрж░рзНржбрж╛рж░рзЗрж░ ржирзЗрждрж╛ ржХрж╛ржЗрж▓рзЛ рж░рзЗржи ржПрж░ рж╣рж╛рждрзЗ ржзрж░рж╛ ржкрж░рзЗржиред ржХрж┐ржирзНрждрзБ ржПрж░ ржЖржЧрзЗ рждрж┐ржирж┐ ржорзНржпрж╛ржк ржЯрж┐ рждрж╛рж░ ржбрзНрж░ржпрж╝рзЗржб, ржмрж┐ ржмрж┐ рзо ржПрж░ ржХрж╛ржЫрзЗ ржЖржорж╛ржиржд рж░рзЗржЦрзЗ ржжрзЗржиред ржмрж┐ ржмрж┐ рзо ржжрзБрж░ржШржЯржирж╛ рж╕рзНржерж▓ ржерзЗржХрзЗ ржжрзВрж░рзЗ рж╕рж░рзЗ ржЖрж╕рж▓рзЗ ржорзНржпрж╛ржк ржЯрж┐ ржХрж╛ржЗрж▓рзЛ рж░рзЗржи ржПрж░ рж╣рж╛рждрзЗ ржпрж╛ржУржпрж╝рж╛ ржерзЗржХрзЗ ржмрзЗржБржЪрзЗ ржпрж╛ржпрж╝ред ржХрж┐ржирзНрждрзБ ржкрзЛ ржХрзЗ ржХрж╛ржЗрж▓рзЛ ржмржирзНржзрж┐ ржХрж░рзЗ ржПржмржВ ржорзНржпрж╛ржкрзЗрж░ ржХржерж╛ ржЬрж┐ржЬрзНржЮрзЗрж╢ ржХрж░рзЗред рждржмрзЗ, ржкрзЛ рждрж╛ ржмрж▓рждрзЗ ржЕрж╕рзНржмрзАржХрзГрждрж┐ ржЬрж╛ржирж╛ржпрж╝ред ржмрж┐ ржмрж┐ рзо ржХрж┐ ржкрж╛рж░ржмрзЗ ржорзНржпрж╛ржк ржЯрж┐ржХрзЗ рж╕ржарж┐ржХ рж╣рж╛рждрзЗ рждрзБрж▓рзЗ ржжрж┐рждрзЗ?</td>\n      <td>ржирж┐ржЙ рж░рж┐ржкрж╛ржмрж▓рж┐ржХ ржорзБржЦрж┐ рж╕рж╛ржорж░рж┐ржХ рж╕ржВрж╕рзНржерж╛рж░ ржирж╛ржо ржХрзА?</td>\n      <td>{'answer_start': [207, 207], 'text': ['рж░рзЗрж╕рж┐рж╕рзНржЯрзЗржирзНрж╕'', 'рж░рзЗрж╕рж┐рж╕рзНржЯрзЗржирзНрж╕'']}</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bn_wiki_2949_01</td>\n      <td>ржмрж╛ржВрж▓рж╛ржжрзЗрж╢ ржирзМржмрж╛рж╣рж┐ржирзА</td>\n      <td>рзирзжрзжрзо рж╕рж╛рж▓рзЗрж░ ржорж╛ржпрж╝рж╛ржиржорж╛рж░ рж╕рж░ржХрж╛рж░ ржжржХрзНрж╖рж┐ржг ржХрзЛрж░рж┐ржпрж╝рж╛ржи ржХрзЛржорзНржкрж╛ржирж┐ ржжрж╛ржЗржпрж╝рзБржХрзЗ рж╕рзЗржЗржирзНржЯ ржорж╛рж░ржЯрж┐ржирзНрж╕ ржжрзНржмрзАржкрзЗрж░ рзлрзж ржиржЯрж┐ржХрзНржпрж╛рж▓ ржорж╛ржЗрж▓ ржжржХрзНрж╖рж┐ржг ржкрж╢рзНржЪрж┐ржорзЗ ржмрж┐рждрж░рзНржХрж┐ржд рж╕ржорзБржжрзНрж░рж╕рзАржорж╛ржпрж╝ рждрзЗрж▓-ржЧрзНржпрж╛рж╕ ржЕржирзБрж╕ржирзНржзрж╛ржирзЗрж░ ржжрж╛ржпрж╝рж┐рждрзНржм ржжрзЗржпрж╝ред рзи ржиржнрзЗржорзНржмрж░ рзирзжрзжрзо, ржжрж╛ржЗржпрж╝рзБ ржмрж┐рждрж░рзНржХрж┐ржд рж╕рзАржорж╛ржпрж╝ ржЕржирзБрж╕ржирзНржзрж╛ржи рж░рж┐ржЧ ржмрж╕рж╛ржпрж╝ред ржмрж╛ржВрж▓рж╛ржжрзЗрж╢ рж╕рж░ржХрж╛рж░ ржорж╛ржпрж╝рж╛ржиржорж╛рж░ржХрзЗ ржЕржирзБрж╕ржирзНржзрж╛ржи ржмржирзНржз ржХрж░рж╛рж░ ржЕржирзБрж░рзЛржз ржЬрж╛ржирж╛ржпрж╝ ржХрж┐ржирзНрждрзБ ржорж╛ржпрж╝рж╛ржиржорж╛рж░рзЗрж░ ржкржХрзНрж╖ ржерзЗржХрзЗ ржХрзЛржи рж╕рж╛рж░рж╛ ржкрж╛ржУржпрж╝рж╛ ржпрж╛ржпрж╝ ржирж┐ред ржкрж░ржмрж░рзНрждрзАрждрзЗ ржмрж╛ржВрж▓рж╛ржжрзЗрж╢ ржирзМржмрж╛рж╣рж┐ржирзА рж╕рзЗржЦрж╛ржирзЗ ржлрзНрж░рж┐ржЧрзЗржЯ ржмрж╛ржирзМржЬрж╛ ржЖржмрзБ ржмржХрж░, ржЯрж╣рж▓ ржЬрж╛рж╣рж╛ржЬ ржмрж╛ржирзМржЬрж╛ ржоржзрзБржорждрж┐ ржПржмржВ ржбрзБржмрзЛржЬрж╛рж╣рж╛ржЬ ржмрж┐ржзрзНржмржВрж╕рзА ржЬрж╛рж╣рж╛ржЬ ржмрж╛ржирзМржЬрж╛ ржирж┐рж░рзНржнржпрж╝ржХрзЗ ржорзЛрждрж╛ржпрж╝рзЗржи ржХрж░рзЗред ржкрж╛рж▓рзНржЯрж╛ ржкржжржХрзНрж╖рзЗржк рж╣рж┐рж╕рзЗржмрзЗ ржорж╛ржпрж╝рж╛ржиржорж╛рж░ ржУ ржжрзБржЗржЯрж┐ ржпрзБржжрзНржзржЬрж╛рж╣рж╛ржЬ ржорзЛрждрж╛ржпрж╝рзЗржи ржХрж░рж▓рзЗ ржпрзБржжрзНржзрж╛ржмрж╕рзНржерж╛рж░ рж╕рзГрж╖рзНржЯрж┐ рж╣ржпрж╝ред ржкрж░ржмрж░рзНрждрзАржХрж╛рж▓рзЗ ржжрзБржЗ ржжрзЗрж╢рзЗрж░ ржоржзрзНржпрзЗ ржХрзВржЯржирзИрждрж┐ржХ ржЖрж▓рзЛржЪржирж╛ рж╢рзБрж░рзБ рж╣ржпрж╝ ржПржмржВ рзн ржиржнрзЗржорзНржмрж░ ржорж╛ржпрж╝рж╛ржиржорж╛рж░ рж░рж┐ржЧ рж╕рж░рж┐ржпрж╝рзЗ ржирзЗржпрж╝ред\\n\\nрзирзжрззрзз рж╕рж╛рж▓рзЗ ржирзМржмрж╛рж╣рж┐ржирзАрж░ ржПржХржЯрж┐ ржЙржжрзНржзрж╛рж░ ржУ ржЪрж┐ржХрж┐рзОрж╕ржХ ржжрж▓ржХрзЗ ржЯрзЛржХрж┐ржУ ржнрзВржорж┐ржХржорзНржк ржУ рж╕рзБржирж╛ржорж┐рж░ ржкрж░ ржЬрж╛ржкрж╛ржирзЗ ржорзЛрждрж╛ржпрж╝рзЗржи ржХрж░рж╛ рж╣ржпрж╝ред рзирзжрззрзй рж╕рж╛рж▓рзЗ ржЯрж╛ржЗржлрзБржи рж╣рж╛ржЗржпрж╝рж╛ржи ржП ржЖржХрзНрж░рж╛ржирзНржд ржорж╛ржирзБрж╖рзЗрж░ рж╕рж╣рж╛ржпрж╝рждрж╛ржпрж╝ рззрзж рж▓ржХрзНрж╖ ржбрж▓рж╛рж░ ржорзВрж▓рзНржпрзЗрж░ ржорж╛ржиржмрж┐ржХ рж╕рж╣рж╛ржпрж╝рждрж╛ рж╕рж░ржЮрзНржЬрж╛ржо ржУ ржирзМржмрж╛рж╣рж┐ржирзАрж░ ржЪрж┐ржХрж┐рзОрж╕ржХ ржжрж▓ рж╕рж╣ ржмрж╛ржирзМржЬрж╛ рж╕ржорзБржжрзНрж░ ржЬржпрж╝ржХрзЗ ржлрж┐рж▓рж┐ржкрж╛ржЗржирзЗ ржорзЛрждрж╛ржпрж╝рзЗржи ржХрж░рж╛ рж╣ржпрж╝ред\\n\\nрзирзжрззрзк рж╕рж╛рж▓рзЗрж░ ржорж╛рж░рзНржЪрзЗ ржмрж╛ржВрж▓рж╛ржжрзЗрж╢ ржирзМржмрж╛рж╣рж┐ржирзА ржирж┐ржЦрзЛржБржЬ ржорж╛рж▓ржпрж╝рзЗрж╢рж┐ржпрж╝рж╛ ржПржпрж╝рж╛рж░рж▓рж╛ржЗржирзНрж╕ ржлрзНрж▓рж╛ржЗржЯ рзйрзнрзж ржПрж░ ржЕржирзБрж╕ржирзНржзрж╛ржи ржЕржнрж┐ржпрж╛ржи рж╢рзБрж░рзБ ржХрж░рзЗ ржлрзНрж░рж┐ржЧрзЗржЯ ржмрж╛ржирзМржЬрж╛ ржЙржорж░ ржлрж╛рж░рзБржХ ржПржмржВ рж╕рж╛ржорзБржжрзНрж░рж┐ржХ ржЯрж╣рж▓ ржмрж┐ржорж╛ржи ржбрж░ржирж┐ржпрж╝рж╛рж░ ржбрж┐ржУ-рзирзирзоржПржиржЬрж┐ ржорзЛрждрж╛ржпрж╝рзЗржирзЗрж░ ржоржзрзНржп ржжрж┐ржпрж╝рзЗред ржмрж┐ржорж╛ржиржЯрж┐ ржЫрж┐рж▓ ржПржХржЯрж┐ ржмрзЛржпрж╝рж┐ржВ рзнрзнрзн-рзирзжрзжржПржЖрж░ ржоржбрзЗрж▓рзЗрж░ ржмрж┐ржорж╛ржи ржпрж╛ рззрзкржЯрж┐ ржжрзЗрж╢рзЗрж░ рзирзирзн ржЬржи ржпрж╛рждрзНрж░рзА ржПржмржВ рззрзи ржЬржи ржХрзНрж░рзБ ржирж┐ржпрж╝рзЗ ржорж╛рж▓ржпрж╝рзЗрж╢рж┐ржпрж╝рж╛ ржерзЗржХрзЗ ржЪрзАржирзЗ ржпрж╛ржЪрзНржЫрж┐рж▓ред ржкрж░ржмрж░рзНрждрзАрждрзЗ ржмрж╛ржирзМржЬрж╛ ржЙржорж░ ржлрж╛рж░рзБржХржХрзЗ ржмрж╛ржирзМржЬрж╛ рж╕ржорзБржжрзНрж░ ржЬржпрж╝ ржжрж┐ржпрж╝рзЗ ржкрзНрж░рждрж┐рж╕рзНржерж╛ржкржи ржХрж░рж╛ рж╣ржпрж╝ред рзирзжрззрзк рж╕рж╛рж▓рзЗрж░ ржорзЗ ржорж╛рж╕рзЗ ржПржХржЯрж┐ ржЕрж╕рзНржЯрзНрж░рзЗрж▓рзАржпрж╝ ржХрзЛржорзНржкрж╛ржирж┐ ржмржЩрзНржЧрзЛржкрж╕рж╛ржЧрж░ ржП ржмрж┐ржорж╛ржиржЯрж┐рж░ ржзрзНржмржВрж╕рж╛ржмрж╢рзЗрж╖ ржкрж╛ржУржпрж╝рж╛рж░ ржжрж╛ржмрж┐ ржХрж░рж▓рзЗ ржЕржирзБрж╕ржирзНржзрж╛ржи ржЕржнрж┐ржпрж╛ржи ржкрзБржирж░рж╛ржпрж╝ рж╢рзБрж░рзБ рж╣ржпрж╝ред\\n\\nрзирзжрззрзк рж╕рж╛рж▓рзЗ ржорж╛рж▓ржжрзНржмрзАржкрзЗрж░ ржкрж╛ржирж┐ рж╕ржВржХржЯрзЗрж░ рж╕ржоржпрж╝ ржмрж╛ржВрж▓рж╛ржжрзЗрж╢ ржирзМржмрж╛рж╣рж┐ржирзА ржЫрж┐рж▓ ржкрзНрж░ржержо ржпрж╛рж░рж╛ ржорж╛ржиржмрж┐ржХ рж╕рж╣рж╛ржпрж╝рждрж╛ рждрзНрж░рж╛ржг ржХрж╛рж░рзНржпржХрзНрж░ржо рж╢рзБрж░рзБ ржХрж░рзЗред рж╕рзЗрж╕ржоржпрж╝ ржмрж╛ржирзМржЬрж╛ рж╕ржорзБржжрзНрж░ ржЬржпрж╝ржХрзЗ рззрзжрзж ржЯржи ржкрж╛ржирж┐рж░ ржмрзЛрждрж▓ рж╕рж╣ ржорзЛрждрж╛ржпрж╝рзЗржи ржХрж░рж╛ рж╣ржпрж╝ред</td>\n      <td>ржжрж╛ржЗржпрж╝рзБ ржХрзЛржи ржжрзЗрж╢рж┐ ржХрзЛржорзНржкрж╛ржирж┐?</td>\n      <td>{'answer_start': [34, 27], 'text': ['ржХрзЛрж░рж┐ржпрж╝рж╛ржи', 'ржжржХрзНрж╖рж┐ржг ржХрзЛрж░рж┐ржпрж╝рж╛ржи']}</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>bn_wiki_2589_02</td>\n      <td>ржирж╛рж░рзА рж╕рзБрж░ржХрзНрж╖рж╛ ржмрж┐рж▓</td>\n      <td>ржирж╛рж░рзА рж╕рзБрж░ржХрзНрж╖рж╛ ржмрж┐рж▓ ржпрж╛ рзирзжрзжрзм рж╕рж╛рж▓рзЗрж░ рззрзлржЗ ржиржнрзЗржорзНржмрж░ ржкрж╛ржХрж┐рж╕рзНрждрж╛ржирзЗрж░ ржЬрж╛рждрзАржпрж╝ ржкрж░рж┐рж╖ржж ржХрж░рзНрждрзГржХ ржкрж╛рж╕ ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрж┐рж▓, рждрж╛ ржкрж╛ржХрж┐рж╕рзНрждрж╛ржирзЗрж░ ржзрж░рзНрж╖ржг ржУ ржмрзНржпржнрж┐ржЪрж╛рж░рзЗрж░ рж╢рж╛рж╕рзНрждрж┐ ржирж┐ржпрж╝ржирзНрждрзНрж░ржгржХрж╛рж░рзА рззрзпрзнрзп рж╕рж╛рж▓рзЗрж░ рж╣рзБржжрзБржж ржЕржзрзНржпрж╛ржжрзЗрж╢ ржЖржЗржиржХрзЗ ржмрзНржпрж╛ржкржХржнрж╛ржмрзЗ рж╕ржорж╛рж▓рзЛржЪрж┐ржд ржХрж░рж╛рж░ ржЪрзЗрж╖рзНржЯрж╛ ржЫрж┐рж▓ред рж╣рзБржжрзБржж ржЕржзрзНржпрж╛ржжрзЗрж╢рзЗрж░ рж╕ржорж╛рж▓рзЛржЪржХрзЗрж░рж╛ ржЕржнрж┐ржпрзЛржЧ ржХрж░рзЗржЫрж┐рж▓рзЗржи ржпрзЗ ржПржЯрж┐ ржзрж░рзНрж╖ржгрзЗрж░ ржЕржнрж┐ржпрзЛржЧ ржкрзНрж░ржорж╛ржг ржХрж░рж╛ржХрзЗ ржЕрждрзНржпржирзНржд ржХржарж┐ржи ржУ ржмрж┐ржкржЬрзНржЬржиржХ ржХрж░рзЗ рждрзБрж▓рзЗржЫрзЗ ржПржмржВ ржмрж┐рж▓ржЯрж┐рж░ ржлрж▓рзЗ рж╣рж╛ржЬрж╛рж░ рж╣рж╛ржЬрж╛рж░ ржирж╛рж░рзА ржХрж╛рж░рж╛ржмрж░ржг ржХрж░рзЗржЫрж┐рж▓рзЗржиред ржмрж┐рж▓ржЯрж┐ ржЬрж┐ржирж╛ ржЕржзрзНржпрж╛ржжрзЗрж╢ ржерзЗржХрзЗ ржкрж╛ржХрж┐рж╕рзНрждрж╛ржи ржкрзЗржирж╛рж▓ ржХрзЛржбрзЗ ржмрзЗрж╢ ржХржпрж╝рзЗржХржЯрж┐ ржЕржкрж░рж╛ржз ржлрж┐рж░рж┐ржпрж╝рзЗ ржжрж┐ржпрж╝рзЗржЫрж┐рж▓, ржпрзЗржЦрж╛ржирзЗ ржПржЗ ржЖржЗржиржЧрзБрж▓рж┐ рззрзпрзнрзп рж╕рж╛рж▓рзЗрж░ ржЖржЧрзЗ ржЫрж┐рж▓, ржПржмржВ ржмрзНржпржнрж┐ржЪрж╛рж░ ржУ ржмрзНржпржнрж┐ржЪрж╛рж░рзЗрж░ ржЕржкрж░рж╛ржзрзЗрж░ ржмрж┐ржЪрж╛рж░рзЗрж░ ржЬржирзНржп ржПржХржЯрж┐ рж╕ржорзНржкрзВрж░рзНржг ржирждрзБржи ржкржжрзНржзрждрж┐ рждрзИрж░рж┐ ржХрж░рзЗржЫрж┐рж▓, рж╢рж╛рж╕рзНрждрж┐ рж╣рж┐рж╕рзЗржмрзЗ ржмрзЗрждрзНрж░рж╛ржШрж╛ржд ржПржмржВ ржЕржЩрзНржЧржЪрзНржЫрзЗржж ржЕржкрж╕рж╛рж░ржг ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрж┐рж▓ред ржЖржЗржирзЗрж░ ржорж╛ржирзЗ рж╣рж▓, ржирж╛рж░рзАрж░рж╛ ржзрж░рзНрж╖ржг ржкрзНрж░ржорж╛ржг ржХрж░рждрзЗ ржирж╛ ржкрж╛рж░рж▓рзЗ ржЬрзЗрж▓ ржЦрж╛ржЯрждрзЗ ржкрж╛рж░ржмрзЗ ржирж╛, ржПржмржВ рж╕рж╛ржХрзНрж╖рзА ржЫрж╛ржбрж╝рж╛ ржЕржирзНржп ржХрзЛржирзЛ ржнрж┐рждрзНрждрж┐рждрзЗ ржзрж░рзНрж╖ржг ржкрзНрж░ржорж╛ржг ржХрж░рж╛рж░ ржЕржирзБржорждрж┐ ржжрзЗржмрзЗ, ржпрзЗржоржи ржлрж░рзЗржирж╕рж┐ржХ ржУ ржбрж┐ржПржиржП ржкрзНрж░ржорж╛ржгред\\n\\nржпрж╛ржЗрж╣рзЛржХ, ржХрж┐ржЫрзБ ржзрж░рзНржорзАржпрж╝ ржжрж▓ ржмрж┐рж▓ржЯрж┐ржХрзЗ ржЕржирзИрж╕рж▓рж╛ржорж┐ржХ ржПржмржВ ржмрж░рзНржзрж┐ржд ржХрж░рзЗ ржЕрж╕рж╛ржВржмрж┐ржзрж╛ржирж┐ржХ ржмрж▓рзЗржЫрзЗ, рждржмрзЗ ржкрж╛ржХрж┐рж╕рзНрждрж╛ржирзЗрж░ рж╕рзБржкрзНрж░рж┐ржо ржХрзЛрж░рзНржЯ ржмрж┐рж▓ржЯрж┐ржХрзЗ 'ржЗрж╕рж▓рж╛ржорзА ржмрж┐ржзрж╛ржи рж▓ржЩрзНржШржи ржХрж░рзЗ' ржПржоржи ржЕржнрж┐ржпрзЛржЧ ржерж╛ржХрж╛ рж╕рждрзНрждрзНржмрзЗржУ ржкрж╛ржХрж┐рж╕рзНрждрж╛ржирзЗрж░ рж╕ржВржмрж┐ржзрж╛ржи ржерзЗржХрзЗ ржмрж╛рждрж┐рж▓ ржХрж░рзЗржирж┐, рждрж╛ржЗ ржЖржЬржУ ржПржЯрж┐ ржЯрж┐ржХрзЗ рж░ржпрж╝рзЗржЫрзЗред ржкрж╛ржХрж┐рж╕рзНрждрж╛ржирзЗрж░ ржкрж╛ржЮрзНржЬрж╛ржм ржкрзНрж░ржжрзЗрж╢ ржЖрж░рзЗржХржЯрж┐ ржирж╛рж░рзА ржмрж┐рж▓ ржкрж╛рж╕ ржХрж░рзЗржЫрзЗ, ржпрж╛ ржЕрж╕рж╛ржВржмрж┐ржзрж╛ржирж┐ржХрждрж╛рж░ ржнрж┐рждрзНрждрж┐рждрзЗ ржЖржжрж╛рж▓рждрзЗ ржмрж┐ржЪрж╛рж░рж╛ржзрзАржи рж░ржпрж╝рзЗржЫрзЗред\\n\\nрзирзжрззрзм рж╕рж╛рж▓рзЗ, ржлрзМржЬржжрж╛рж░рж┐ ржЖржЗржи (рж╕ржВрж╢рзЛржзржи) (ржзрж░рзНрж╖ржгрзЗрж░ ржЕржкрж░рж╛ржз) ржЕржзрж┐ржирж┐ржпрж╝ржо рзирзжрззрзм ржкрж╛ржХрж┐рж╕рзНрждрж╛ржирзЗрж░ рж╕ржВрж╕ржжрзЗ ржкрж╛рж╕ рж╣ржпрж╝рзЗржЫрзЗ, ржпрж╛ ржзрж░рзНрж╖ржг ржУ рж╕ржорзНржорж╛ржи рж░ржХрзНрж╖рж╛ржпрж╝ рж╣рждрзНржпрж╛рж░ ржЕржкрж░рж╛ржзрзАржжрзЗрж░ ржХржарзЛрж░ рж╢рж╛рж╕рзНрждрж┐ ржкрзНрж░ржмрж░рзНрждржи ржХрж░рзЗред ржирждрзБржи ржЖржЗржи ржнрзБржХрзНрждржнрзЛржЧрзАржжрзЗрж░ ржЖржЗржирж┐ рж╕рж╣рж╛ржпрж╝рждрж╛ ржкрзНрж░ржжрж╛ржи ржХрж░рзЗржЫрзЗ ржПржмржВ ржзрж░рзНрж╖ржгрзЗрж░ ржХрзНрж╖рзЗрждрзНрж░рзЗ ржбрж┐ржПржиржП ржкрж░рзАржХрзНрж╖рж╛ ржмрж╛ржзрзНржпрждрж╛ржорзВрж▓ржХ ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗред ржЖржЗржирзЗ ржкрзБрж▓рж┐рж╢ржХрзЗ ржзрж░рзНрж╖ржи ржмрж╛ ржпрзМржи рж╣ржпрж╝рж░рж╛ржирж┐рж░ рж╢рж┐ржХрж╛рж░ ржирж╛рж░рзА ржмрзЗржБржЪрзЗ ржерж╛ржХрж╛ ржмрзНржпржХрзНрждрж┐рж░ ржмржХрзНрждржмрзНржп ржкрзБрж▓рж┐рж╢ржжрзЗрж░ ржкрзБрж▓рж┐рж╢ ржХрж░рзНржоржХрж░рзНрждрж╛рж░ ржЙржкрж╕рзНржерж┐рждрж┐рждрзЗ ржиржерж┐ржнрзБржХрзНржд ржХрж░рждрзЗржУ ржмрж▓рж╛ рж╣ржпрж╝рзЗржЫрзЗред ржирждрзБржи ржЖржЗржирзЗ ржнрзБржХрзНрждржнрзЛржЧрзА ржУ рж╕рж╛ржХрзНрж╖рзАржжрзЗрж░ ржмрж┐ржмрзГрждрж┐ ржиржерж┐ржнрзБржХрзНржд ржХрж░рж╛рж░ ржЬржирзНржп ржнрж┐ржбрж┐ржУ рж▓рж┐ржЩрзНржХрзЗрж░ ржорждрзЛ ржкрзНрж░ржпрзБржХрзНрждрж┐рж░ ржмрзНржпржмрж╣рж╛рж░рзЗрж░ ржЕржирзБржорждрж┐ ржжрзЗржУржпрж╝рж╛ рж╣ржмрзЗ, ржпрж╛рждрзЗ рждрж╛ржжрзЗрж░ ржЖржжрж╛рж▓рждрзЗ рж╣рж╛ржЬрж┐рж░ рж╣ржпрж╝рзЗ ржХрзЛржирзЛ ржЕржкржорж╛ржи ржмрж╛ ржЭрзБржБржХрж┐рж░ рж╕ржорзНржорзБржЦрзАржи рж╣рждрзЗ ржирж╛ рж╣ржпрж╝ред ржирждрзБржи ржЖржЗржиржЯрж┐ ржЗржЙржПржи ржЙржЗржорзЗржирзЗрж░ ржирж┐рж░рзНржмрж╛рж╣рзА ржкрж░рж┐ржЪрж╛рж▓ржХ ржлрзБржоржЬрж┐рж▓ ржорж╛рж▓рзНржмрзЛ-ржПржиржЧрзБржХрж╛ ржжрзНржмрж╛рж░рж╛ ржкрзНрж░рж╢ржВрж╕рж╛ ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрж┐рж▓ред</td>\n      <td>рж╣рзБржжрзБржж ржЕржзрзНржпрж╛ржжрзЗрж╢рзЗрж░ рж╕ржорж╛рж▓рзЛржЪржХрзЗрж░рж╛ ржХрзА ржЕржнрж┐ржпрзЛржЧ ржХрж░рзЗржЫрж┐рж▓рзЗржи ?</td>\n      <td>{'answer_start': [264, 264], 'text': ['ржПржЯрж┐ ржзрж░рзНрж╖ржгрзЗрж░ ржЕржнрж┐ржпрзЛржЧ ржкрзНрж░ржорж╛ржг ржХрж░рж╛ржХрзЗ ржЕрждрзНржпржирзНржд ржХржарж┐ржи ржУ ржмрж┐ржкржЬрзНржЬржиржХ ржХрж░рзЗ рждрзБрж▓рзЗржЫрзЗ ржПржмржВ ржмрж┐рж▓ржЯрж┐рж░ ржлрж▓рзЗ рж╣рж╛ржЬрж╛рж░ рж╣рж╛ржЬрж╛рж░ ржирж╛рж░рзА ржХрж╛рж░рж╛ржмрж░ржг ржХрж░рзЗржЫрж┐рж▓рзЗржи', 'ржПржЯрж┐ ржзрж░рзНрж╖ржгрзЗрж░ ржЕржнрж┐ржпрзЛржЧ ржкрзНрж░ржорж╛ржг ржХрж░рж╛ржХрзЗ ржЕрждрзНржпржирзНржд ржХржарж┐ржи ржУ ржмрж┐ржкржЬрзНржЬржиржХ ржХрж░рзЗ рждрзБрж▓рзЗржЫрзЗ ржПржмржВ ржмрж┐рж▓ржЯрж┐рж░ ржлрж▓рзЗ рж╣рж╛ржЬрж╛рж░ рж╣рж╛ржЬрж╛рж░ ржирж╛рж░рзА ржХрж╛рж░рж╛ржмрж░ржг ржХрж░рзЗржЫрж┐рж▓рзЗржи']}</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>bn_wiki_1757_01</td>\n      <td>ржЕрзНржпрж╛рж▓рж┐рж╕ (ржЖржЬржм ржжрзЗрж╢рзЗ ржЕрзНржпрж╛рж▓рж┐рж╕рзЗрж░ ржжрзБржГрж╕рж╛рж╣рж╕рзАржХ ржЕржнрж┐ржпрж╛ржи)</td>\n      <td>ржЕрзНржпрж╛рж▓рж┐рж╕ ржЪрж░рж┐рждрзНрж░ржЯрж┐ржХрзЗ ржЕрзНржпрж╛рж▓рж┐рж╕ рж▓рж┐ржбрзЗрж▓ рж╣рж┐рж╕рзЗржмрзЗ ржкрзНрж░рждрж┐ржкржирзНржи ржХрж░рж╛рж░ ржмрзНржпрж╛ржкрж╛рж░ржЯрж╛ ржпржерзЗрж╖рзНржЯ ржмрж┐рждрж░рзНржХрж┐рждред ржмрж╣рзБ рж╕ржорж╛рж▓рзЛржЪржХ ржЪрж░рж┐рждрзНрж░ржЯрж┐ржХрзЗ ржЕрзНржпрж╛рж▓рж┐рж╕ рж▓рж┐ржбрзЗрж▓ ржмрж╛ рждрж╛рж░ ржжрзНржмрж╛рж░рж╛ ржЕржирзБржкрзНрж░рж╛ржгрж┐ржд ржмрж▓рзЗ ржоржирзЗ ржХрж░рзЗржиред ржЕржирзНржпржжрж┐ржХрзЗ ржЖржмрж╛рж░ ржПрж░ ржмрж┐рж░рзЛржзрзЗ ржЕржирзЗржХрзЗ ржмрж▓рзЗржи ржпрзЗ, ржХрзНржпрж╛рж░рж▓ рждрж╛рж░ ржЧрж▓рзНржкрзЗрж░ ржорзБржЦрзНржп ржЪрж░рж┐рждрзНрж░ ржУ рж▓рж┐ржбрзЗрж▓ржХрзЗ ржкрзГржержХ ржоржирзЗ ржХрж░рзЗржиред ржХрзНржпрж╛рж░рж▓рзЗрж░ ржорждрзЗ, рждрж╛рж░ ржЪрж░рж┐рждрзНрж░ржЯрж┐ ржмрж╛рж╕рзНрждржмрзЗрж░ ржХрзЛржирзЛ рж╢рж┐рж╢рзБрж░ ржУржкрж░ ржнрж┐рждрзНрждрж┐ ржХрж░рзЗ ржирж┐рж░рзНржорж┐ржд рж╣ржпрж╝ржирж┐, ржПржЯрж┐ рж╕ржорзНржкрзВрж░рзНржг ржПржХржЯрж┐ ржХрж╛рж▓рзНржкржирж┐ржХ ржЪрж░рж┐рждрзНрж░ред ржЕрзНржпрж╛рж▓рж┐рж╕тАЩ ржЕрзНржпрж╛ржбржнрзЗржЮрзНржЪрж╛рж░рзНрж╕ ржЗржи ржУржпрж╝рж╛ржирзНржбрж╛рж░рж▓рзНржпрж╛ржирзНржб-ржПрж░ ржкрзНрж░ржержо ржЦрж╕ржбрж╝рж╛ ржЕрзНржпрж╛рж▓рж┐рж╕тАЩ ржЕрзНржпрж╛ржбржнрзЗржЮрзНржЪрж╛рж░рзНрж╕ ржЖржирзНржбрж╛рж░ржЧрзНрж░рж╛ржЙржирзНржб-ржП ржЕрзНржпрж╛рж▓рж┐рж╕ ржЪрж░рж┐рждрзНрж░ржЯрж┐рж░ ржкрзНрж░ржержо ржЖржмрж┐рж░рзНржнрж╛ржмред рззрзорзмрзи рж╕рж╛рж▓рзЗрж░ рзкржарж╛ ржЬрзБрж▓рж╛ржЗржпрж╝рзЗрж░ ржПржХ рж╕ржирзНржзрзНржпрж╛ржпрж╝ ржмржирзНржзрзБ рж░ржмрж┐ржирж╕ржи ржбрж╛ржХржУржпрж╝рж╛рж░рзНрже-ржПрж░ рж╕рж╛ржерзЗ ржирзМржХрж╛ржнрзНрж░ржоржгржХрж╛рж▓рзЗ рж▓рж┐ржбрзЗрж▓ ржмрзЛржирзЗржжрзЗрж░ ржоржирзЛрж░ржЮрзНржЬржирзЗрж░ ржЬржирзНржп ржЧрж▓рзНржк ржмрж▓рж╛ рж╢рзБрж░рзБ ржХрж░рзЗржиред ржПржЗ ржзрж╛рж░рж╛ ржкрж░ржмрж░рзНрждрзА ржирзМржХрж╛ржмрж┐рж╣рж╛рж░рзЗржУ ржмржЬрж╛ржпрж╝ ржЫрж┐рж▓ ржПржмржВ ржПржЦрж╛ржи ржерзЗржХрзЗржЗ ржПржЗ ржЖржирзНржбрж╛рж░ржЧрзНрж░рж╛ржЙржирзНржб ржХрж╛рж╣рж┐ржирж┐ржЯрж┐рж░ ржЙрзОржкрждрзНрждрж┐ред ржкрж░рзЗ ржжрж╢ржо ржмрж░рзНрж╖рзАржпрж╝рж╛ ржЕрзНржпрж╛рж▓рж┐рж╕ рж▓рж┐ржбрзЗрж▓рзЗрж░ ржЖржмржжрж╛рж░рзЗ ржХрзНржпрж╛рж░рж▓ ржЧрж▓рзНржкржЯрж┐ржХрзЗ рж▓рж┐ржЦрж┐ржд рж░рзБржк ржжрзЗржи, ржпрж╛ рззрзорзмрзй рж╕рж╛рж▓рзЗрж░ ржлрзЗржмрзНрж░рзБржпрж╝рж╛рж░рж┐рждрзЗ рж╕ржорзНржкржирзНржи рж╣ржпрж╝ред ржЖржирзНржбрж╛рж░ржЧрзНрж░рж╛ржЙржирзНржб ржЧрж▓рзНржкрзЗ рзйрзнржЯрж┐ ржЫржмрж┐ рж░ржпрж╝рзЗржЫрзЗ, ржпрж╛рж░ ржоржзрзНржпрзЗ рзирзнржЯрж┐рждрзЗ ржЕрзНржпрж╛рж▓рж┐рж╕ рж░ржпрж╝рзЗржЫрзЗред ржЫржмрж┐рж░ ржЕрзНржпрж╛рж▓рж┐рж╕рзЗрж░ рж╕ржЩрзНржЧрзЗ ржЕрзНржпрж╛рж▓рж┐рж╕ рж▓рж┐ржбрзЗрж▓рзЗрж░ ржЦрзБржм рж╕рж╛ржорж╛ржирзНржп ржорж┐рж▓ ржерж╛ржХрж╛ржпрж╝ ржзрж░рж╛ рж╣ржпрж╝ ржпрзЗ ржЕрзНржпрж╛рж▓рж┐рж╕рзЗрж░ ржЫрзЛржЯрзЛ ржмрзЛржи ржПржбрж┐ржержХрзЗ рж╣ржпрж╝рждрзЛ ржПржЗ ржЫржмрж┐рж░ ржЬржирзНржп ржоржбрзЗрж▓ рж╣рж┐рж╕рзЗржмрзЗ ржирзЗржУржпрж╝рж╛ рж╣ржпрж╝рзЗржЫрж┐рж▓ред ржХрзНржпрж╛рж░рж▓рзЗрж░ ржЕрзНржпрж╛рж▓рж┐рж╕ ржЯрж┐ржЙржирж┐ржХ ржкрж░рзЗ ржЕржирзНржпржжрж┐ржХрзЗ рж▓рж┐ржбрзЗрж▓ ржмрзЛржирзЗрж░рж╛ рж╕рзЗрж▓рж╛ржЗ ржХрж░рж╛ ржХрж╛ржкржбрж╝ ржкрж░рждред ржЧрж▓рзНржкрзЗрж░ ржЫржмрж┐ржЧрзБрж▓рж┐рждрзЗ ржкрзНрж░рж╛ржХ-рж░рж╛ржлрж╛ржпрж╝рзЗрж▓рзАржпрж╝ ржЪрж┐рждрзНрж░ржХрж░ ржжрж╛ржирзНрждрзЗ ржЧрзЗржмрзНрж░рж┐ржпрж╝рзЗрж▓ рж░рзЛрж╕рзЗржЯрж┐ ржПржмржВ ржЖрж░рзНржерж╛рж░ рж╣рж┐ржЙржЬ-ржПрж░ ржпржерзЗрж╖рзНржЯ ржкрзНрж░ржнрж╛ржм рж▓ржХрзНрж╖ ржХрж░рж╛ ржпрж╛ржпрж╝ред рззрзорзмрзк рж╕рж╛рж▓рзЗрж░ ржиржнрзЗржорзНржмрж░рзЗ ржХрзНржпрж╛рж░рж▓ рждрж╛рж░ рж╣рж╛рждрзЗ рж▓рзЗржЦрж╛ ржЕрзНржпрж╛рж▓рж┐рж╕тАЩ ржЕрзНржпрж╛ржбржнрзЗржЮрзНржЪрж╛рж░рзНрж╕ ржЖржирзНржбрж╛рж░ржЧрзНрж░рж╛ржЙржирзНржб ржмржЗржЯрж┐ ржЕрзНржпрж╛рж▓рж┐рж╕ рж▓рж┐ржбрзЗрж▓ржХрзЗ ржЙржкрж╣рж╛рж░ ржжрзЗржиред</td>\n      <td>рж╕ржорж╛рж▓рзЛржЪржХржжрзЗрж░ ржорждрзЗ ржЕрзНржпрж╛рж▓рж┐рж╕ ржХрзЛржи ржЪрж░рж┐рждрзНрж░ ржерзЗржХрзЗ ржЕржирзБржкрзНрж░рж╛ржгрж┐ржд?</td>\n      <td>{'answer_start': [19, 19], 'text': ['ржЕрзНржпрж╛рж▓рж┐рж╕ рж▓рж┐ржбрзЗрж▓', 'ржЕрзНржпрж╛рж▓рж┐рж╕ рж▓рж┐ржбрзЗрж▓']}</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>bn_wiki_0822_02</td>\n      <td>ржЖрж▓рзЗржХржЬрж╛ржирзНржбрж╛рж░ ржЧрзНрж░рж╛рж╣рж╛ржо ржмрзЗрж▓</td>\n      <td>рждржЦржи рждрж┐ржирж┐ рждрж╛рж░ ржмрж╛ржмрж╛рж░ ржХрж╛ржЫрзЗ рждрж╛рж░ ржмржбрж╝ ржжрзБржЗ ржнрж╛ржЗржпрж╝рзЗрж░ ржоржзрзНржпржирж╛ржорзЗрж░ ржоржд ржПржХржЯрж┐ ржоржзрзНржпржирж╛ржорзЗрж░ ржЬржирзНржп ржЖржмржжрж╛рж░ ржХрж░рзЗржиред рждрж╛рж░ ржПржЧрж╛рж░рзЛ рждржо ржЬржирзНржоржжрж┐ржирзЗ рждрж╛рж░ ржмрж╛ржмрж╛ ржЖрж▓рзЗржХржЬрж╛ржирзНржбрж╛рж░ ржорзЗрж▓ржнрж┐рж▓ ржмрзЗрж▓ рждрж╛рж░ржЗ ржПржХ ржХрж╛ржирж╛ржбрж┐ржпрж╝рж╛ржи ржмржирзНржзрзБрж░ ржирж╛ржо ржЕржгрзБрж╢рж╛рж░рзЗ рждрж╛рж░ ржЫрзЛржЯ ржЫрзЗрж▓рзЗрж░ ржоржзрзНржп ржирж╛ржо рж░рж╛ржЦрзЗржи ржЧрзНрж░рж╛рж╣рж╛ржоред ржПрж░ ржкрж░ ржерзЗржХрзЗржЗ рждрж╛рж░ ржирж╛ржо рж╣ржпрж╝ ржЖрж▓рзЗржХржЬрж╛ржирзНржбрж╛рж░ ржЧрзНрж░рж╛рж╣рж╛ржо ржмрзЗрж▓ред рждржмрзЗ ржорзГрждрзНржпрзБрж░ ржЖржЧ ржкрж░рзНржпржирзНржд рждрж╛рж░ ржкрж░рж┐ржмрж╛рж░рзЗрж░ рж╕ржжрж╕рзНржп ржПржмржВ ржмржирзНржзрзБрж░рж╛ ржПрж▓рзЗржХ ржирж╛ржорзЗржЗ ржбрж╛ржХрждред\\r\\nржнрж╛ржЗржжрзЗрж░ ржоржд ржЖрж▓рзЗржХржЬрж╛ржирзНржбрж╛рж░ржУ ржЫрзЛржЯржмрзЗрж▓рж╛ржпрж╝ ржкрж░рж┐ржмрж╛рж░рзЗ ржмрж╛ржмрж╛рж░ ржХрж╛ржЫ ржерзЗржХрзЗржЗ рж╢рж┐ржХрзНрж╖рж╛ рж▓рж╛ржн ржХрж░рзЗред ржпржжрж┐ржУ ржЦрзБржм ржЕрж▓рзНржк ржмржпрж╝рж╕рзЗржЗ рждрж╛ржХрзЗ ржПржбрж┐ржиржмрж╛рж░рзНржЧрзЗрж░ рж░ржпрж╝рзЗрж▓ рж╣рж╛ржЗ рж╕рзНржХрзБрж▓рзЗ ржнрж░рзНрждрж┐ ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрж┐рж▓, рж╕рзЗржЦрж╛ржирзЗ рждрж┐ржирж┐ ржЪрж╛рж░ ржХрзНрж▓рж╛рж╕ ржкрж░рзНржпржирзНрждржЗ ржкржбрж╝рж╛рж╢рзЛржирж╛ ржХрж░рзЗржи ржПржмржВ ржорж╛рждрзНрж░ рззрзл ржмржЫрж░ ржмржпрж╝рж╕рзЗржЗ рж╕рзНржХрзБрж▓ ржЫрзЗржбрж╝рзЗ ржжрзЗржиред рж╕рзНржХрзБрж▓рзЗ рждрж╛рж░ ржлрж▓рж╛ржлрж▓ ржЦрзБржм ржПржХржЯрж╛ ржнрж╛рж▓ ржЫрж┐рж▓ ржирж╛ ржПржмржВ ржкрзНрж░рж╛ржпрж╝рж╢ржЗ рж╕рзНржХрзБрж▓ ржХрж╛ржорж╛ржЗ ржжрзЗржУржпрж╝рж╛рж░ ржкрзНрж░ржмржгрждрж╛ ржжрзЗржЦрж╛ ржЧрж┐ржпрж╝рзЗржЫрзЗред рждрж╛рж░ ржмрж╛ржмрж╛рж░ ржЙржЪрзНржЪрж╛рж╢рж╛ рж╕рждрзНрждрзНржмрзЗржУ рж╕рзНржХрзБрж▓рзЗрж░ ржкрж╛ржарзНржпржмрж┐рж╖ржпрж╝ржЧрзБрж▓рзЛрж░ ржкрзНрж░рждрж┐ ржЖрж▓рзЗржХржЬрж╛ржирзНржбрж╛рж░рзЗрж░ ржХрзЛржи ржЖржЧрзНрж░рж╣ржЗ ржЫрж┐рж▓ ржирж╛ ржмрж░ржВ ржмрж┐ржЬрзНржЮрж╛ржи ржПржмржВ ржмрж┐рж╢рзЗрж╖ ржХрж░рзЗ ржЬрзАржмржмрж┐ржЬрзНржЮрж╛ржирзЗ рждрж╛рж░ ржорж╛рж░рж╛рждрзНржмржХ ржЖржЧрзНрж░рж╣ ржЫрж┐рж▓ред рж╕рзНржХрзБрж▓ рждрзНржпрж╛ржЧ ржХрж░рж╛рж░ ржкрж░ ржЖрж▓рзЗржХржЬрж╛ржирзНржбрж╛рж░ рждрж╛рж░ ржжрж╛ржжрж╛рж░ рж╕рж╛ржерзЗ ржмрж╕ржмрж╛рж╕ ржХрж░рж╛рж░ ржЬржирзНржп рж▓ржирзНржбржирзЗ ржЧржоржи ржХрж░рзЗржиред рж▓ржирзНржбржирзЗ рждрж╛рж░ ржжрж╛ржжрж╛рж░ рж╕рж╛ржерзЗ ржерж╛ржХрж╛рж░ рж╕ржоржпрж╝ ржкрж░рж╛рж╢рзБржирж╛рж░ ржкрзНрж░рждрж┐ рждрж╛рж░ ржЧржнрзАрж░ ржнрж╛рж▓ржмрж╛рж╕рж╛ ржЬржирзНржорж╛ржпрж╝ ржПржмржВ ржкрзНрж░рж╛ржпрж╝рж╢ржЗ рждрж╛рж░ ржжрж╛ржжрж╛рж░ рж╕рж╛ржерзЗ ржмрж┐ржнрж┐ржирзНржи ржмрж┐рж╖ржпрж╝рзЗрж░ ржЙржкрж░ ржЖрж▓рзЛржЪржирж╛ ржПржмржВ ржкрж░рж╛рж╢рзБржирж╛ ржХрж░рзЗ рждрж╛рж░ ржШржгрзНржЯрж╛рж░ ржкрж░ ржШржгрзНржЯрж╛ ржХрзЗржЯрзЗ ржпрзЗрждред ржжрж╛ржжрж╛ ржЖрж▓рзЗржХржЬрж╛ржирзНржбрж╛рж░ ржмрзЗрж▓ рждрж╛рж░ ржирж╛рждрж┐ржХрзЗ рждрж╛рж░ржЗ рж╢рж┐ржХрзНрж╖рж╛ржиржмрж┐рж╢ рж╢рж┐рж╖рзНржп рж╣рж┐рж╕рзЗржмрзЗ ржЧрзНрж░рж╣ржг ржХрж░рзЗржи ржПржмржВ рждрж╛ржХрзЗ ржПржЗ ржмрж┐рж╖ржпрж╝рзЗрж░ ржкрзНрж░рж╢рж┐ржХрзНрж╖ржХ рж╣рж┐рж╕рзЗржмрзЗ ржЧржбрж╝рзЗ рждрзЛрж▓рж╛рж░ ржЬржирзНржп ржХржарзЛрж░ ржкрж░рж┐рж╢рзНрж░ржо ржХрж░рзЗржиред ржорж╛рждрзНрж░ рззрзм ржмржЫрж░ ржмржпрж╝рж╕рзЗржЗ ржЖрж▓рзЗржХржЬрж╛ржирзНржбрж╛рж░ рж╢рж┐ржХрзНрж╖рж╛ржиржмрж┐рж╢ рж╢рж┐ржХрзНрж╖ржХ рж╣рж┐рж╕рзЗржмрзЗ рж╕рзНржХржЯрж▓рзНржпрж╛ржирзНржбрзЗрж░ ржУржпрж╝рзЗрж╕рзНржЯржи рж╣рж╛ржЙрж╕ ржПржХрж╛ржбрзЗржорж┐рждрзЗ ржпрзЛржЧржжрж╛ржи ржХрж░рзЗржиред ржпржжрж┐ржУ рждржЦржи рждрж┐ржирж┐ рж▓рзНржпрж╛ржЯрж┐ржи ржПржмржВ ржЧрзНрж░рж┐ржХ ржнрж╛рж╖рж╛рж░ ржЫрж╛рждрзНрж░ ржЫрж┐рж▓рзЗржи, рждрж┐ржирж┐ рждрж╛рж░ ржкрж░рж┐ржЪрж╛рж▓рж┐ржд ржкрзНрж░рждрзНрждрзЗржХржЯрж┐ ржХрзНрж▓рж╛рж╕рзЗрж░ ржЬржирзНржп рззрзж ржкрж╛ржЙржирзНржб ржХрж░рзЗ ржкрзЗрждрзЗржиред ржПрж░ ржкрж░рзЗрж░ ржмржЫрж░ рждрж┐ржирж┐ ржПржбрж┐ржиржмрж░рж╛ ржмрж┐рж╢рзНржмржмрж┐ржжрзНржпрж╛рж▓ржпрж╝рзЗ ржнрж░рзНрждрж┐ рж╣ржи ржпрзЗржЦрж╛ржирзЗ рждрж╛рж░ ржмржбрж╝ ржнрж╛ржЗржУ ржкржбрж╝рзЗржЫрж┐рж▓рзЗржиред рззрзорзмрзо рж╕рж╛рж▓рзЗ рж╕рзНржмржкрж░рж┐ржмрж╛рж░рзЗ ржХрж╛ржирж╛ржбрж╛ ржЪрж▓рзЗ ржпрж╛ржУржпрж╝рж╛рж░ ржЖржЧрзЗ рждрж┐ржирж┐ рж▓ржирзНржбржи ржмрж┐рж╢рзНржмржмрж┐ржжрзНржпрж╛рж▓ржпрж╝ ржерзЗржХрзЗ рждрж╛рж░ ржорзНржпрж╛ржЯрзНрж░рж┐ржХрзБрж▓рзЗрж╢ржи рж╕ржорзНржкржирзНржи ржХрж░рзЗржЫрж┐рж▓рзЗржиред</td>\n      <td>ржмрзЗрж▓ ржХрждржмржЫрж░ ржмржпрж╝рж╕рзЗ рж╕рзНржХрзБрж▓ ржЫрзЗржбрж╝рзЗ ржжрзЗржи?\\r</td>\n      <td>{'answer_start': [542, 542], 'text': ['рззрзл', 'рззрзл']}</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>bn_wiki_2639_03</td>\n      <td>ржзрж░рзНрж╖ржг рж╕ржВрж╕рзНржХрзГрждрж┐</td>\n      <td>ржзрж░рзНрж╖ржг рж╕ржВрж╕рзНржХрзГрждрж┐ ржПржХржЯрж┐ ржирж┐рж╖рзНржкрждрзНрждрж┐рж░ рж╕ржорж╛ржЬрждрж╛рждрзНрждрзНржмрж┐ржХ рждрждрзНрждрзНржм, ржпрзЗржЦрж╛ржирзЗ рж▓рж┐ржЩрзНржЧ ржУ ржпрзМржирждрж╛ рж╕ржорзНржкрж░рзНржХрзЗ рж╕рж╛ржорж╛ржЬрж┐ржХ ржоржирзЛржнрж╛ржмрзЗрж░ ржХрж╛рж░ржгрзЗ ржзрж░рзНрж╖ржг ржмрзНржпрж╛ржкржХ ржУ рж╕рзНржмрж╛ржнрж╛ржмрж┐ржХ рж╣ржпрж╝ред  рж╕рж╛ржзрж╛рж░ржгржд ржзрж░рзНрж╖ржг рж╕ржВрж╕рзНржХрзГрждрж┐рж░ рж╕рж╛ржерзЗ ржЬржбрж╝рж┐ржд ржЖржЪрж░ржгржЧрзБрж▓рж┐рж░ ржоржзрзНржпрзЗ рж░ржпрж╝рзЗржЫрзЗ ржнрж┐ржХржЯрж┐ржоржХрзЗ ржжрзЛрж╖рж╛рж░рзЛржк ржХрж░рж╛, ржмрзЗрж╢рзНржпрж╛-рж▓ржЬрзНржЬрж╛ ржжрзЗржУржпрж╝рж╛, ржпрзМржи ржмрж╕рзНрждрзБ рж╣рж┐рж╕рж╛ржмрзЗ рждрзБрж▓рзЗ ржзрж░рж╛, ржзрж░рзНрж╖ржгржХрзЗ рждрзБржЪрзНржЫ ржХрж░рж╛, ржмрзНржпрж╛ржкржХ ржзрж░рзНрж╖ржгржХрзЗ ржЕрж╕рзНржмрзАржХрж╛рж░ ржХрж░рж╛, ржпрзМржи рж╕рж╣рж┐ржВрж╕рждрж╛рж░ ржХрж╛рж░ржгрзЗ ржХрзНрж╖рждрж┐ рж╕рзНржмрзАржХрж╛рж░ ржХрж░рждрзЗ ржЕрж╕рзНржмрзАржХрж╛рж░ ржХрж░рж╛, ржЕржержмрж╛ ржПржЧрзБрж▓рж┐рж░ рж╕ржВржорж┐рж╢рзНрж░ржгред  ржПржЯрж┐ ржЬрзЗрж▓ ржзрж░рзНрж╖ржг рж╕рж╣ рж╕рж╛ржорж╛ржЬрж┐ржХ ржЧрзЛрж╖рзНржарзАрж░ ржоржзрзНржпрзЗ ржЖржЪрж░ржг ржмрж░рзНржгржирж╛ ржУ ржмрзНржпрж╛ржЦрзНржпрж╛ ржХрж░рж╛рж░ ржЬржирзНржп ржмрзНржпржмрж╣рж╛рж░ ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗ ржПржмржВ ржпрзБржжрзНржзрзЗрж░ ржзрж╛рж░рж╛ ржпрзЗржЦрж╛ржирзЗ ржоржирж╕рзНрждрж╛рждрзНрждрзНржмрж┐ржХ ржпрзБржжрзНржз рж╣рж┐рж╕рж╛ржмрзЗ ржмрзНржпржмрж╣рзГржд рж╣ржпрж╝ред рж╕ржоржЧрзНрж░ рж╕ржорж╛ржЬржХрзЗ ржзрж░рзНрж╖ржг рж╕ржВрж╕рзНржХрзГрждрж┐ ржмрж▓рзЗ ржЕржнрж┐ржпрзЛржЧ ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗред  ржПржЯрж┐ ржзрж░рзНрж╖ржгрзЗрж░ ржХрж▓рзНржкржирж╛ ржПржмржВ ржзрж░рзНрж╖ржгрзЗрж░ ржкрж░рзНржирзЛржЧрзНрж░рж╛ржлрж┐рж░ рж╕рж╛ржерзЗ ржЬржбрж╝рж┐рждред\\n\\nржзрж░рзНрж╖ржг рж╕ржВрж╕рзНржХрзГрждрж┐рж░ ржзрж╛рж░ржгрж╛ржЯрж┐ ржжрзНржмрж┐рждрзАржпрж╝ рждрж░ржЩрзНржЧрзЗрж░ ржирж╛рж░рзАржмрж╛ржжрзАржжрзЗрж░ ржжрзНржмрж╛рж░рж╛ рждрзИрж░рж┐ рж╣ржпрж╝рзЗржЫрж┐рж▓, ржкрзНрж░рж╛ржержорж┐ржХржнрж╛ржмрзЗ ржзрж╛рж░ржирж╛ржЯрж┐ ржпрзБржХрзНрждрж░рж╛рж╖рзНржЯрзНрж░рзЗ рззрзпрзнрзж-ржПрж░ ржжрж╢ржХрзЗ рж╢рзБрж░рзБ рж╣ржпрж╝рзЗржЫрж┐рж▓ред ржзрж╛рж░ржгрж╛рж░ рж╕ржорж╛рж▓рзЛржЪржХрж░рж╛ ржПрж░ ржЕрж╕рзНрждрж┐рждрзНржм ржмрж╛ ржмрзНржпрж╛ржкрзНрждрж┐ ржирж┐ржпрж╝рзЗ ржмрж┐рждрж░рзНржХ ржХрж░рзЗржи, ржпрзБржХрзНрждрж┐ ржжрзЗржи ржпрзЗ ржзрж╛рж░ржгрж╛ржЯрж┐ ржЦрзБржм рж╕ржВржХрзАрж░рзНржг, ржпржжрж┐ржУ ржПржоржи ржХрж┐ржЫрзБ рж╕ржВрж╕рзНржХрзГрждрж┐ ржЖржЫрзЗ ржпрзЗржЦрж╛ржирзЗ ржзрж░рзНрж╖ржг ржмрзНржпрж╛ржкржХ ржнрж╛ржмрзЗ ржкрж░рж┐рж▓ржХрзНрж╖рж┐ржд рж╣ржпрж╝, ржзрж░рзНрж╖ржг рж╕ржВрж╕рзНржХрзГрждрж┐рж░ ржзрж╛рж░ржгрж╛ржЯрж┐ ржмрзЛржЭрж╛рждрзЗ ржкрж╛рж░рзЗ ржпрзЗ ржзрж░рзНрж╖ржХ ржжрзЛрж╖рзА ржиржпрж╝ ржмрж░ржВ рж╕ржорж╛ржЬ ржзрж░рзНрж╖ржгржХрзЗ рж╕ржХрзНрж╖ржо ржХрж░рзЗред\\n\\nржЕржирзЗржХ ржЖржирзНржжрзЛрж▓ржи ржзрж░рзНрж╖ржг рж╕ржВрж╕рзНржХрзГрждрж┐рж░ рж╕ржорзНржмрзЛржзржи ржХрж░рзЗржЫрзЗ, ржпрзЗржоржи рж╕рзНрж▓рж╛ржЯ ржУржпрж╝рж╛ржХ ржУ ржорж┐ ржЯрзБ ред ржПржЗ \" ржорж┐ ржЯрзБ \" ржЖржирзНржжрзЛрж▓ржиржЯрж┐ ржкрзНрж░ржержо рзирзжрзжрзм рж╕рж╛рж▓рзЗ ржЖржорзЗрж░рж┐ржХрж╛ржи ржХрж░рзНржорзА ржУ ржпрзМржи ржирж┐ржкрзАржбрж╝ржирзЗрж░ ржмрзЗржБржЪрзЗ ржерж╛ржХрж╛ рждрж╛рж░рж╛ржирж╛ ржмрж╛рж░рзНржХ ржХрж░рзНрждрзГржХ рж╕ржВржЧржарж┐ржд рж╣ржпрж╝ред ржПржЗ ржЖржирзНржжрзЛрж▓ржиржЧрзБрж▓рж┐ ржзрж░рзНрж╖ржгрзЗрж░ рж╕рж╛ржерзЗ ржорзВрж░рзНржд ржУ рж╕ржВржпрзБржХрзНржд рж╣рзНржпрж╛рж╢ржЯрзНржпрж╛ржЧрзЗрж░ ржорж╛ржзрзНржпржорзЗ ржорж╛ржирзБрж╖рзЗрж░ ржЧрж▓рзНржк рж╢рзЗржпрж╝рж╛рж░ ржХрж░рждрзЗ рж╕рж╛рж╣рж╛ржпрзНржп  ржУ ржПржХржЯрж┐ ржЕржирж▓рж╛ржЗржи рж╕рзНржерж╛ржи ржкрзНрж░ржжрж╛ржи ржХрж░рзЗржЫрзЗ, ржпрзЗржЦрж╛ржирзЗ ржмрж┐ржнрж┐ржирзНржи ржзрж░ржирзЗрж░ ржпрзМржи рж╕рж╣рж┐ржВрж╕рждрж╛рж░ рж╢рж┐ржХрж╛рж░ рж╣ржУржпрж╝рж╛ ржмрзНржпржХрзНрждрж┐рж░рж╛ рждрж╛ржжрзЗрж░ ржЧрж▓рзНржк ржмрж▓рждрзЗ ржкрж╛рж░рзЗ ржПржмржВ ржПржХрзЗ ржЕржкрж░ржХрзЗ ржмрж┐рж╢рзНржмрж╛рж╕ ржХрж░рждрзЗ ржкрж╛рж░рзЗред\\n\\nржзрж░рзНрж╖ржг рж╕ржВрж╕рзНржХрзГрждрж┐ ржирж╛рж░рзА ржУ ржкрзБрж░рзБрж╖ ржЙржнржпрж╝рзЗрж░ ржЬржирзНржпржЗ ржХрзНрж╖рждрж┐ржХрж░ ржмрж▓рзЗ ржмрж░рзНржгржирж╛ ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗред ржЬрзНржпрж╛ржХрж╕ржи ржХрж╛рждржЬ, ржорж╛ржЗржХрзЗрж▓ ржХрж┐ржорзЗрж▓ ржУ ржбржи ржорзНржпрж╛ржХржлрж╛рж░рж╕ржирзЗрж░ ржорждрзЛ ржХрж┐ржЫрзБ рж▓рзЗржЦржХ ржУ ржмржХрзНрждрж╛рж░рж╛ ржмрж▓рзЗржЫрзЗржи ржпрзЗ ржПржЯрж┐ рж▓рж┐ржЩрзНржЧрзЗрж░ ржнрзВржорж┐ржХрж╛ржЧрзБрж▓рж┐рж░ рж╕рж╛ржерзЗ рж╕рзНржмрждржирзНрждрзНрж░ржнрж╛ржмрзЗ ржпрзБржХрзНржд, ржпрж╛ ржкрзБрж░рзБрж╖ржжрзЗрж░ ржЖрждрзНржо-ржкрзНрж░ржХрж╛рж╢ржХрзЗ рж╕рзАржорж╛ржмржжрзНржз ржХрж░рзЗ ржПржмржВ ржкрзБрж░рзБрж╖ржжрзЗрж░ ржорж╛ржирж╕рж┐ржХ ржХрзНрж╖рждрж┐ ржХрж░рзЗред  рж░рж╛рж╖рзНржЯрзНрж░ржмрж┐ржЬрзНржЮрж╛ржирзА ржЖржЗрж░рж┐рж╕ ржорзНржпрж╛рж░рж┐ржпрж╝ржи ржЗржпрж╝ржВ-ржПрж░ ржорждрзЗ, ржзрж░рзНрж╖ржг рж╕ржВрж╕рзНржХрзГрждрж┐рж░ рж╢рж┐ржХрж╛рж░ рж╣ржУржпрж╝рж╛ ржмрзНржпрж╛ржХрзНрждрж┐рж░рж╛ ржирж┐ржкрзАржбрж╝ржиржорзВрж▓ржХ ржпрзМржи рж╕рж╣рж┐ржВрж╕рждрж╛рж░ рж▓ржХрзНрж╖рзНржпрж╣рзАржи ржХрж░рзНржорзЗрж░ ржнржпрж╝рзЗ ржмрж╕ржмрж╛рж╕ ржХрж░рзЗржи, ржпрж╛ рж╢рж┐ржХрж╛рж░ рж╣ржУржпрж╝рж╛ ржмрзНржпрж╛ржХрзНрждрж┐ржжрзЗрж░ ржХрзНрж╖рждрж┐ржЧрзНрж░рж╕рзНржд ржмрж╛ ржЕржкржорж╛ржирж┐ржд ржХрж░рж╛рж░ ржЙржжрзНржжрзЗрж╢рзНржпрзЗ ржХрж░рж╛ рж╣ржпрж╝ред  ржЕржирзНржпрж░рж╛ ржзрж░рзНрж╖ржг рж╕ржВрж╕рзНржХрзГрждрж┐ржХрзЗ ржЖржзрзБржирж┐ржХрзАржХрж░ржг ржПржмржВ рж╢рж┐рж▓рзНржкрж╛ржпрж╝ржирзЗрж░ рж╕рж╛ржерзЗ ржпрзБржХрзНржд ржХрж░рзЗ, ржпрзБржХрзНрждрж┐ ржжрзЗржпрж╝ ржпрзЗ ржкрзНрж░рж╛ржХ-рж╢рж┐рж▓рзНржк рж╕ржорж╛ржЬрзЗ \"ржзрж░рзНрж╖ржг ржорзБржХрзНржд\" рж╕ржВрж╕рзНржХрзГрждрж┐ ржЫрж┐рж▓, ржпрзЗрж╣рзЗрждрзБ ржПржЗ рж╕ржорж╛ржЬржЧрзБрж▓рж┐рждрзЗ ржорж╣рж┐рж▓рж╛ржжрзЗрж░ ржирж┐ржорзНржи ржорж░рзНржпрж╛ржжрж╛ рждрж╛ржжрзЗрж░ ржпрзМржи рж╕рж╣рж┐ржВрж╕рждрж╛ ржерзЗржХрзЗ ржХрж┐ржЫрзБржЯрж╛ ржкрзНрж░рждрж┐рж░рзЛржз ржжрзЗржпрж╝ред рж╢рж┐рж▓рзНржк ржзрж░рзНрж╖ржг рж╕ржВрж╕рзНржХрзГрждрж┐рждрзЗ ржирж╛рж░рзАрж░рж╛ рждрж╛ржжрзЗрж░ ржЧрзГрж╣рж╕рзНржерж╛рж▓рзАрж░ ржнрзВржорж┐ржХрж╛ ржерзЗржХрзЗ ржмрзЗрж░рж┐ржпрж╝рзЗ ржЖрж╕рзЗ ржПржмржВ ржХрж░рзНржоржХрзНрж╖рзЗрждрзНрж░ ржУ ржЕржирзНржпрж╛ржирзНржп ржЕржЮрзНржЪрж▓рзЗ ржРрждрж┐рж╣рзНржпржЧрждржнрж╛ржмрзЗ ржкрзБрж░рзБрж╖ржжрзЗрж░ ржжрзНржмрж╛рж░рж╛ ржкрзНрж░ржнрж╛ржмрж┐ржд рж╣ржпрж╝рзЗ ржжрзГрж╢рзНржпржорж╛ржи рж╣ржпрж╝рзЗ ржУржарзЗ, ржкрзБрж░рзБрж╖рзЗрж░ ржирж┐рж░рж╛ржкрждрзНрждрж╛рж╣рзАржирждрж╛ ржмрзГржжрзНржзрж┐ ржкрж╛ржпрж╝, ржпрж╛рж░ ржлрж▓рзЗ рждрж╛рж░рж╛ ржзрж░рзНрж╖ржгржХрзЗ ржмрзНржпржмрж╣рж╛рж░ ржХрж░рзЗ ржирж╛рж░рзАржХрзЗ ржжржоржи ржХрж░рзЗред рж╣рзНржпрж╛ржБ</td>\n      <td>ржзрж░рзНрж╖ржг рж╕ржВрж╕рзНржХрзГрждрж┐рж░ ржзрж╛рж░ржгрж╛ржЯрж┐ ржХрж┐ ржжрзНржмрж┐рждрзАржпрж╝ рждрж░ржЩрзНржЧрзЗрж░ ржирж╛рж░рзАржмрж╛ржжрзАржжрзЗрж░ ржжрзНржмрж╛рж░рж╛ рждрзИрж░рж┐ рж╣ржпрж╝рзЗржЫрж┐рж▓ ?</td>\n      <td>{'answer_start': [2420, 2420], 'text': ['рж╣рзНржпрж╛ржБ', 'рж╣рзНржпрж╛ржБ']}</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>bn_wiki_0494_02</td>\n      <td>ржШрзВрж░рзНржгржХ ржЧрзБржкрзНрждрж▓рж┐ржЦржи ржпржирзНрждрзНрж░</td>\n      <td>ржПржХржЯрж┐ ржорзЗрж╢рж┐ржи рждрзИрж░рж┐ ржХрж░рж╛рж░ ржЬржирзНржп рждрзБрж▓ржирж╛ржпрж╝ ржПржЯрж┐ рж╕рж╣ржЬ ржкрзНрж░рждрж┐рж╕рзНржерж╛ржкржи рж╕рж╣ржЬржмрзЛржзрзНржпред ржЖржорж░рж╛ рзирзмржЯрж┐ рж▓рж╛ржЗржЯ ржмрж╛рж▓рзНржм рж╕ржВржпрзБржХрзНржд рзирзмржЯрж┐ рж╕рзБржЗржЪ ржПрж░ рж╕ржЩрзНржЧрзЗ ржПржХржЯрж┐ ржмрзИржжрзНржпрзБрждрж┐ржХ рж╕рж┐рж╕рзНржЯрзЗржо ржмрж┐ржмрзЗржЪржирж╛ ржХрж░рждрзЗ ржкрж╛рж░рзЗржи;ржпржЦржи ржЖржкржирж┐ ржХрзЛржи рж╕рзБржЗржЪ ржЪрж╛рж▓рзБ ржХрж░рзЗржи,ржмрж╛рж▓рзНржмрзЗрж░ ржЖрж▓рзЛ ржЖрж▓рзЛржХрж┐ржд рж╣ржпрж╝ред ржкрзНрж░рждрж┐ржЯрж┐ рж╕рзБржЗржЪ ржПржХржЯрж┐ ржЯрж╛ржЗржкрж░рж╛ржЗржЯрж╛рж░ ржПржХржЯрж┐ ржХрзА(ржЪрж╛ржмрж┐) ржжрзНржмрж╛рж░рж╛ ржкрж░рж┐ржЪрж╛рж▓рж┐ржд рж╣ржпрж╝ ржПржмржВ ржмрж╛рж▓рзНржмржХрзЗ ржЕржХрзНрж╖рж░ ржжрж┐ржпрж╝рзЗ рж▓рзЗржмрзЗрж▓ ржХрж░рж╛ рж╣ржпрж╝,рждрж╛рж░ржкрж░ ржПржЗ ржзрж░ржирзЗрж░ ржПржХржЯрж┐ рж╕рж┐рж╕рзНржЯрзЗржо ржХрзА ржПржмржВ ржХрзА-ржмрзЛрж░рзНржбрзЗрж░ ржоржзрзНржпрзЗ рждрж╛рж░рзЗрж░ ржУржпрж╝рж╛рж░рж┐ржВ ржирж┐рж░рзНржмрж╛ржЪржи ржХрж░рзЗ ржПржиржХрзНрж░рж┐ржкрзНржЯрзЗрж╢ржирзЗрж░ ржЬржирзНржп ржмрзНржпржмрж╣рж╛рж░ ржХрж░рж╛ ржпрзЗрждрзЗ ржкрж╛рж░рзЗ: ржЙржжрж╛рж╣рж░ржгрж╕рзНржмрж░рзВржк,ржП ржЕржХрзНрж╖рж░ржЯрж┐ ржЯрж╛ржЗржк ржХрж░рж▓рзЗ ржЖрж▓рзЛрж░ ржХрж┐ржЙ рж▓рзЗржмрзЗрж▓ржЯрж┐ рж▓рж╛ржЗржЯ ржЖржк ржХрж░ржмрзЗред ржпрж╛ржЗрж╣рзЛржХ, ржУржпрж╝рзНржпрж╛рж░рж┐ржВ рж╕ржВрж╢рзЛржзржи ржХрж░рзЗ,рж╕рж╛ржорж╛ржирзНржп ржирж┐рж░рж╛ржкрждрзНрждрж╛ ржкрзНрж░ржжрж╛ржи ржХрж░рж╛ рж╣ржпрж╝ред\\nрж░ржЯрж╛рж░ ржорзЗрж╢рж┐ржирзЗ ржПржЗ ржзрж╛рж░ржгрж╛ржЯрж┐ ржирж┐рж░рзНржорж╛ржг ржХрж░рж╛ рж╣ржпрж╝,ржЖрж╕рж▓рзЗ ржкрзНрж░рждрж┐ржЯрж┐ ржХрзА рж╕рзНржЯрзНрж░рзЛржХ ржПрж░ рж╕ржЩрзНржЧрзЗ рждрж╛рж░рзЗрж░ ржкрж░рж┐ржмрж░рзНрждржиред ржУржпрж╝рзНржпрж╛рж░рж┐ржВ ржПржХржЯрж┐ рж░ржЯрж╛рж░ ржнрж┐рждрж░рзЗ рж╕рзНржерж╛ржкржи ржХрж░рж╛ рж╣ржпрж╝ ржПржмржВ рждрж╛рж░ржкрж░ ржПржХржЯрж┐ ржЕржХрзНрж╖рж░ ржЪрж╛ржкрж╛ рж╣ржпрж╝ ржкрзНрж░рждрж┐ржЯрж┐ ржПржХржЯрж┐ ржЧрж┐ржпрж╝рж╛рж░рзЗрж░ рж╕ржЩрзНржЧрзЗ ржШрзБрж░рждрзЗ ржерж╛ржХрзЗред рждрж╛ржЗ ржкрзНрж░ржержоржмрж╛рж░ ржП ржЪрж╛ржкрж▓рзЗ ржкрзНрж░ржержоржмрж╛рж░ ржПржХржЯрж┐ ржХрж┐ржЙ рждрзИрж░рж┐ рж╣ржпрж╝,ржкрж░ржмрж░рзНрждрзА рж╕ржоржпрж╝рзЗ ржПржЯрж┐ ржЬрзЗ рждрзИрж░рж┐ ржХрж░рждрзЗ ржкрж╛рж░рзЗред ржХрзАржмрзЛрж░рзНржбрзЗрж░ ржЪрж╛ржкрзЗ ржкрзНрж░рждрж┐ржЯрж┐ ржЕржХрзНрж╖рж░ рж░ржЯрж╛рж░ржЯрж┐ржХрзЗ рж╕рзНржкрж┐ржи ржХрж░ржмрзЗ ржПржмржВ ржПржХржЯрж┐ ржкрж▓рж┐ржЕрзНржпрж╛рж▓рзНржлрж╛ржмрзЗржЯрж┐ржХ ржкрзНрж░рждрж┐рж╕рзНржерж╛ржкржи рж╕рж╛ржЗржлрж╛рж░ ржмрж╛рж╕рзНрждржмрж╛ржпрж╝ржи ржХрж░ржмрзЗред\\nрж░ржЯрж╛рж░ ржЖржХрж╛рж░рзЗрж░ ржЙржкрж░ ржирж┐рж░рзНржнрж░ ржХрж░рзЗ,ржПржЯрж┐ рж╣рж╛рждрзЗрж░ рж╕рж╛ржЗржлрж╛рж░ржЧрзБрж▓рж┐рж░ ржерзЗржХрзЗ ржирж┐рж░рж╛ржкржж рж╣рждрзЗ ржкрж╛рж░рзЗ ржирж╛ред ржпржжрж┐ рж░ржЯрж╛рж░ржЯрж┐рж░ ржЙржкрж░рзЗ рж╢рзБржзрзБржорж╛рждрзНрж░ рзирзмржЯрж┐ ржЕржХрзНрж╖рж░ ржЕржмрж╕рзНржерж╛ржи ржерж╛ржХрзЗ,ржкрзНрж░рждрж┐ржЯрж┐ ржЕржХрзНрж╖рж░рзЗрж░ ржЬржирзНржп ржПржХ,рждрж╛рж╣рж▓рзЗ рж╕ржорж╕рзНржд ржмрж╛рж░рзНрждрж╛ржЧрзБрж▓рж┐ ржПржХржЯрж┐ (ржкрзБржирж░рж╛ржмрзГрждрзНрждрж┐) ржХрзА, рзирзм ржЕржХрзНрж╖рж░ ржжрзАрж░рзНржШ ржерж╛ржХржмрзЗред ржпржжрж┐ржУ ржорзВрж▓ржЯрж┐ (ржмрзЗрж╢рж┐рж░ржнрж╛ржЧржЗ рж░ржЯрж╛рж░рзЗрж░ ржУржпрж╝рзНржпрж╛рж░рж┐ржВржЧрзБрж▓рж┐рждрзЗ рж▓рзБржХрж╛ржирзЛ) рж╕ржорзНржнржмржд ржирж╛ржУ рж╣рждрзЗ ржкрж╛рж░рзЗ, рждржмрзЗ ржПржЗ ржзрж░ржирзЗрж░ рж╕рж╛ржЗржлрж╛рж░ржжрзЗрж░ ржЖржХрзНрж░ржоржгрзЗрж░ ржкржжрзНржзрждрж┐ржЧрзБрж▓рж┐рж░ рждржерзНржп ржкрзНрж░ржпрж╝рзЛржЬржи рж╣ржпрж╝ ржирж╛ред рж╕рзБрждрж░рж╛ржВ ржпржЦржи ржПржХржЯрж┐ ржПржХржХ рж░ржЯрж╛рж░ ржорзЗрж╢рж┐ржи ржмрзНржпржмрж╣рж╛рж░ ржХрж░рж╛ рж╕рж╣ржЬ,ржПржЯрж┐ ржЕржирзНржп ржХрзЛржи ржЖржВрж╢рж┐ржХ ржкрж▓рж┐ржЕрзНржпрж╛рж▓рзНржлрж╛ржмрзЗржЯрж┐ржХ рж╕рж╛ржЗржлрж╛рж░ рж╕рж┐рж╕рзНржЯрзЗржорзЗрж░ ржЪрзЗржпрж╝рзЗ ржЖрж░ рж╕рзБрж░ржХрзНрж╖рж┐ржд ржиржпрж╝ред\\nржХрж┐ржирзНрждрзБ ржПржЯрж╛ ржарж┐ржХ ржХрж░рж╛ рж╕рж╣ржЬред ржХрзЗржмрж▓ ржПржХрзЗ ржЕржкрж░рзЗрж░ ржкрж╛рж╢рзЗ рж░ржЯрж╛рж░ рж╕рзНржЯрзНржпрж╛ржХ ржПржмржВ рждрж╛ржжрзЗрж░ ржПржХрж╕ржЩрзНржЧрзЗ ржЧрж┐ржпрж╝рж╛рж░ред ржкрзНрж░ржержо рж░ржЯрж╛рж░ рж╕рзНржкрж┐ржи ржкрж░рзЗ ржПржЯрж┐ ржкрж╛рж╢рж╛ржкрж╛рж╢рж┐ рж░ржЯрж╛рж░ ржПржХржЯрж┐ ржЕржмрж╕рзНржерж╛ржи рж╕рзНржкрж┐ржи ржХрж░рждрзЗ рж╣ржмрзЗред ржПржЦржи ржЖржкржирж╛рж░ ржХрзА(ржЪрж╛ржмрж┐) ржкрзБржирж░рж╛ржмрзГрждрзНрждрж┐ ржХрж░рж╛рж░ ржЖржЧрзЗ рзирзм├Чрзирзм = рзмрзнрзмржЯрж┐ ржЕржХрзНрж╖рж░ (рж▓рзНржпрж╛ржЯрж┐ржи ржмрж░рзНржгржорж╛рж▓рж╛рж░ ржЬржирзНржп) ржЯрж╛ржЗржк ржХрж░рждрзЗ рж╣ржмрзЗ,ржПржмржВ ржПржЦржирзЛ ржПржЯрж┐ рж╢рзБржзрзБржорж╛рждрзНрж░ ржЖржкржирж╛ржХрзЗ рж╕рзЗржЯ ржХрж░рж╛рж░ ржЬржирзНржп ржжрзБржЯрж┐ ржЕржХрзНрж╖рж░рзЗрж░/рж╕ржВржЦрзНржпрж╛ржЧрзБрж▓рж┐рж░ ржПржХржЯрж┐ ржХрзА ржпрзЛржЧрж╛ржпрзЛржЧ ржХрж░рждрзЗ рж╣ржмрзЗред ржпржжрж┐ рзмрзнрзмржЯрж┐ рж▓рж╛ржЗржирзЗрж░ ржПржХржЯрж┐ ржХрзА ржпржерзЗрж╖рзНржЯ ржирж╛ рж╣ржпрж╝, рждржмрзЗ ржЖрж░рзЗржХржЯрж┐ рж░ржЯрж╛рж░ ржпрзЛржЧ ржХрж░рж╛ ржпрж╛ржмрзЗ,ржлрж▓рзЗ рззрзн,рзлрзнрзм ржЕржХрзНрж╖рж░ ржжрзАрж░рзНржШ рж╣ржмрзЗред\\nржПржирж╕рж╛ржЗржлрж╛рж░рзЗрж░ ржорждрзЛ ржкрж╛ржарзНржпржмржЗржпрж╝рзЗрж░ ржорждрзЛ рж╕рж╣ржЬ рж╕рж░рж▓ рж╣ржУржпрж╝рж╛рждрзЗ,ржХрж┐ржЫрзБ рж░ржЯрж╛рж░ ржорзЗрж╢рж┐ржиржЧрзБрж▓рж┐,ржмрж┐рж╢рзЗрж╖ ржХрж░рзЗ ржПржирж┐ржЧржорж╛ ржорзЗрж╢рж┐ржиржЯрж┐,ржЕржирзБржнрзВржорж┐ржХржнрж╛ржмрзЗ ржбрж┐ржЬрж╛ржЗржи ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗ,ржпрзЗржоржи ржПржХржЗ рж╕рзЗржЯрж┐ржВрж╕ ржжрж┐ржпрж╝рзЗ ржжрзБржмрж╛рж░ ржПржиржХрзНрж░рж┐ржкрзНржЯ ржХрж░рзЗ ржЖрж╕рж▓ ржмрж╛рж░рзНрждрж╛рж░ ржкрзБржирж░рж╛ржмрзГрждрзНрждрж┐ред</td>\n      <td>рж░ржЯрж╛рж░ ржХрж┐рж╕рзЗрж░ ржЙржкрж░ ржирж┐рж░рзНржнрж░ ржХрж░рзЗ?</td>\n      <td>{'answer_start': [956, 956], 'text': ['ржЖржХрж╛рж░рзЗрж░', 'ржЖржХрж╛рж░рзЗрж░']}</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>bn_wiki_0898_02</td>\n      <td>ржирж┐ржЙржХрзНрж▓рзАржпрж╝ ржЧржмрзЗрж╖ржгрж╛рж░ ржЬржирзНржп ржЗржЙрж░рзЛржкрзАржпрж╝ рж╕ржВрж╕рзНржерж╛</td>\n      <td>ржирж┐ржЙржХрзНрж▓рзАржпрж╝ ржЧржмрзЗрж╖ржгрж╛рж░ ржЬржирзНржп ржЗржЙрж░рзЛржкрзАржпрж╝ рж╕ржВрж╕рзНржерж╛ ржПржХржЯрж┐ ржЗржЙрж░рзЛржкрзАржпрж╝ ржЧржмрзЗрж╖ржгрж╛ рж╕ржВрж╕рзНржерж╛ ржпрж╛ ржмрж┐рж╢рзНржмрзЗрж░ рж╕рж░рзНржмржмрзГрж╣рзО ржХржгрж╛ ржкржжрж╛рж░рзНржержмрж┐ржЬрзНржЮрж╛ржи ржЧржмрзЗрж╖ржгрж╛ржЧрж╛рж░ ржкрж░рж┐ржЪрж╛рж▓ржирж╛ржпрж╝ ржирж┐ржпрж╝рзЛржЬрж┐рждред рж╕ржВрж╕рзНржерж╛ржЯрж┐рж░ ржорзВрж▓ ржлрж░рж╛рж╕рж┐ ржирж╛ржо рж╣рж▓ ржЕрж░рзНржЧрж╛ржирж┐ржЬрж╛рж╕рж┐ржУржБ ржУрж░рзЛржкрзЗржПржи ржкрзБрж░ рж▓рж╛ рж░рж╢рзЗрж░рзНрж╢ ржирзНржпрзБржХрзНрж▓рзЗржпрж╝рзНржпрж╛рж░, рждржмрзЗ ржлрж░рж╛рж╕рж┐рждрзЗ ржПржЯрж┐ рж╕ржВржХрзНрж╖рзЗржкрзЗ рж╕рзЗрж░рзНржи ржирж╛ржорзЗржЗ ржмрзЗрж╢рж┐ ржкрж░рж┐ржЪрж┐рждред ржЗржВрж░рзЗржЬрж┐рждрзЗ рж╕ржВрж╕рзНржерж╛ржЯрж┐рж░ ржирж╛ржо ржЗржЙрж░рзЛржкрж┐ржпрж╝рж╛ржи ржЕрж░рзНржЧрж╛ржирж╛ржЗржЬрзЗрж╢ржи ржлрж░ ржирж┐ржЙржХрзНрж▓рж┐ржпрж╝рж╛рж░ рж░рж┐рж╕рж╛рж░рзНржЪ, рждржмрзЗ рж╕ржВржХрзНрж╖рзЗржкрзЗ ржлрж░рж╛рж╕рж┐ \"рж╕рзЗрж░рзНржи\" ржЖржжрзНржпржХрзНрж╖рж░рж╛ржЯрж┐ржХрзЗ ржЗржВрж░рзЗржЬрж┐рж░ ржорждрзЛ ржХрж░рзЗ \"рж╕рж╛рж░рзНржи\" ржЙржЪрзНржЪрж╛рж░ржг ржХрж░рж╛ рж╣ржпрж╝ред рж╕ржВрж╕рзНржерж╛ржЯрж┐рж░ ржЖржжрж┐ ржлрж░рж╛рж╕рж┐ ржирж╛ржо ржХрзЛржБрж╕рзЗржЗ ржУрж░рзЛржкрзЗржпрж╝рж╛ржБ ржкрзБрж░ рж▓рж╛ рж░рж╢рзЗрж░рзНрж╢ ржирзНржпрзБржХрзНрж▓рзЗржпрж╝рзНржпрж╛рж░ -ржПрж░ ржЖржжрзНржпржХрзНрж╖рж░ ржЪрждрзБрж╖рзНржЯржпрж╝ рж╕рж┐, ржП, рж░, ржУ ржи ржерзЗржХрзЗ  рж╕рзЗрж░рзНржи ржЖржжрзНржпржХрзНрж╖рж░рж╛ржЯрж┐рж░ ржЙрзОржкрждрзНрждрж┐, ржпрж╛рж░ ржмрж╛ржВрж▓рж╛ ржЕрж░рзНрже рж╣ржпрж╝ \"ржирж┐ржЙржХрзНрж▓рзАржпрж╝ ржЧржмрзЗрж╖ржгрж╛рж░ ржЬржирзНржп ржЗржЙрж░рзЛржкрзАржпрж╝ ржкрж░рж┐рж╖ржж\"ред\\nрж╕ржВрж╕рзНржерж╛ржЯрж┐ ржлрзНрж░рж╛ржирзНрж╕ ржУ рж╕рзБржЗржЬрж╛рж░рж▓рзНржпрж╛ржирзНржбрзЗрж░ рж╕рзАржорж╛ржирзНрждрзЗрж░ ржХрж╛ржЫрзЗ рж╕рзБржЗржЬрж╛рж░рж▓рзНржпрж╛ржирзНржбрзЗрж░ ржлрж░рж╛рж╕рж┐ржнрж╛рж╖рзА ржЬрзЗржирзЗржнрж╛ рж╢рж╣рж░рзЗрж░ ржЙрждрзНрждрж░-ржкрж╢рзНржЪрж┐ржорзЗрж░ ржПржХржЯрж┐ рж╢рж╣рж░рждрж▓рзА ржорзЗрж░рж╛ржБ ржкрзМрж░рж╕ржнрж╛рждрзЗ ржЕржмрж╕рзНржерж┐рждред рззрзпрзлрзк рж╕рж╛рж▓рзЗрж░ рзирзпрж╢рзЗ рж╕рзЗржкрзНржЯрзЗржорзНржмрж░ рждрж╛рж░рж┐ржЦрзЗ ржЕржирзБрж╖рзНржарж┐ржд ржПржХ рж╕ржнрж╛ржпрж╝ рж╕рзЗрж░рзНржи ржкрзНрж░рждрж┐рж╖рзНржарж╛рж░ ржкрзНрж░рж╕рзНрждрж╛ржмржЯрж┐ рж╕рзНржмрж╛ржХрзНрж╖рж░рж┐ржд рж╣ржпрж╝ред ржкрзНрж░рж╕рзНрждрж╛ржмрзЗ рж╕рзНржмрж╛ржХрзНрж╖рж░ржХрж╛рж░рзА рж░рж╛рж╖рзНржЯрзНрж░рзЗрж░ рж╕ржВржЦрзНржпрж╛ рж╢рзБрж░рзБрждрзЗ ржорж╛рждрзНрж░ рззрзи ржерж╛ржХрж▓рзЗржУ ржмрж░рзНрждржорж╛ржирзЗ ржПржЗ рж╕ржжрж╕рзНржп рж░рж╛рж╖рзНржЯрзНрж░рзЗрж░ рж╕ржВржЦрзНржпрж╛ ржмрзЗржбрж╝рзЗ рзирзй-ржП ржжрж╛ржБржбрж╝рж┐ржпрж╝рзЗржЫрзЗред ржПржжрзЗрж░ ржоржзрзНржпрзЗ ржЗрж╕рж░рж╛ржпрж╝рзЗрж▓ ржПржХржорж╛рждрзНрж░ ржЕ-ржЗржЙрж░рзЛржкрзАржпрж╝ рж░рж╛рж╖рзНржЯрзНрж░ рж╣рж┐рж╕рзЗржмрзЗ ржкрзВрж░рзНржг рж╕ржжрж╕рзНржпрзЗрж░ ржорж░рзНржпрж╛ржжрж╛ рж▓рж╛ржн ржХрж░рзЗржЫрзЗред рж╕рзЗрж░рзНржи ржЬрж╛рждрж┐рж╕ржВржШрзЗрж░ рж╕рж╛ржзрж╛рж░ржг ржкрж░рж┐рж╖ржжрзЗрж░ ржЖржирзБрж╖рзНржарж╛ржирж┐ржХ ржкрж░рзНржпржмрзЗржХрзНрж╖ржХрж╕ржорзВрж╣рзЗрж░ ржПржХржЯрж┐ред\\nрж╕рзЗрж░рзНржирзЗрж░ ржЧржмрзЗрж╖ржгрж╛ржЧрж╛рж░рзЗ рзирзжрззрзп рж╕рж╛рж▓рзЗ рзи рж╣рж╛ржЬрж╛рж░ рзм рж╢рждрзЗрж░ржУ ржмрзЗрж╢рж┐ ржмрж┐ржЬрзНржЮрж╛ржирзА, ржХрж╛рж░рж┐ржЧрж░ ржУ ржкрзНрж░рж╢рж╛рж╕ржирж┐ржХ ржХрж░рзНржоржЪрж╛рж░рзА ржХрж░рзНржорж░ржд ржЫрж┐рж▓рзЗржиред рж╕рзЗ ржмржЫрж░ ржмрж┐рж╢рзНржмрзЗрж░ рзнрзжржЯрж┐рж░ ржмрзЗрж╢рж┐ ржжрзЗрж╢рзЗ ржмрж┐ржнрж┐ржирзНржи ржЧржмрзЗрж╖ржгрж╛ рж╕ржВрж╕рзНржерж╛ ржерзЗржХрзЗ ржЖржЧржд рззрзи рж╣рж╛ржЬрж╛рж░ рзк рж╢ржд ржмрзНржпржмрж╣рж╛рж░ржХрж╛рж░рзА ржПржЦрж╛ржирзЗ ржХрж╛ржЬ ржХрж░рзЗржиред ржЧржмрзЗрж╖ржгрж╛ржЧрж╛рж░рзЗрж░ ржкрж░рзАржХрзНрж╖рж╛ржЧрзБрж▓рж┐ ржерзЗржХрзЗ ржкрзНрж░рждрж┐ржжрж┐ржи ржЧржбрж╝рзЗ ржПржХ ржкрзЗржЯрж╛ржмрж╛ржЗржЯ ржЙржкрж╛рждрзНржд (рззрзж рж▓ржХрзНрж╖ ржЧрж┐ржЧрж╛ржмрж╛ржЗржЯ) ржкрзНрж░ржХрзНрж░рж┐ржпрж╝рж╛ржЬрж╛ржд ржХрж░рж╛ рж╣ржпрж╝ред ржПрж░ ржоржзрзНржпрзЗ ржкрзНрж░рждрж┐ ржмржЫрж░ ржкрзНрж░рж╛ржпрж╝ рззрззрзл ржкрзЗржЯрж╛ржмрж╛ржЗржЯ ржЙржкрж╛рждрзНржд рж╕ржВрж░ржХрзНрж╖ржг ржХрж░рзЗ рж░рж╛ржЦрж╛ рж╣ржпрж╝ред</td>\n      <td>рж╕ржВрж╕рзНржерж╛ржЯрж┐рж░ ржорзВрж▓ ржлрж░рж╛рж╕рж┐ ржирж╛ржо ржХрзА?</td>\n      <td>{'answer_start': [163, 163], 'text': ['ржЕрж░рзНржЧрж╛ржирж┐ржЬрж╛рж╕рж┐ржУржБ ржУрж░рзЛржкрзЗржПржи ржкрзБрж░ рж▓рж╛ рж░рж╢рзЗрж░рзНрж╢ ржирзНржпрзБржХрзНрж▓рзЗржпрж╝рзНржпрж╛рж░', 'ржЕрж░рзНржЧрж╛ржирж┐ржЬрж╛рж╕рж┐ржУржБ ржУрж░рзЛржкрзЗржПржи ржкрзБрж░ рж▓рж╛ рж░рж╢рзЗрж░рзНрж╢ ржирзНржпрзБржХрзНрж▓рзЗржпрж╝рзНржпрж╛рж░']}</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>bn_wiki_1336_04</td>\n      <td>ржХрж░рж╛ржЪрж┐ ржЪрзЗржорзНржмрж╛рж░ ржЕржл ржХржорж╛рж░рзНрж╕ ржЕрзНржпрж╛ржирзНржб ржЗржирзНржбрж╛рж╕рзНржЯрзНрж░рж┐</td>\n      <td>ржХрж░рж╛ржЪрж┐ ржЪрзЗржорзНржмрж╛рж░ ржЕржл ржХржорж╛рж░рзНрж╕ ржЕрзНржпрж╛ржирзНржб ржЗржирзНржбрж╛рж╕рзНржЯрзНрж░рж┐ (ржХрзЗрж╕рж┐рж╕рж┐ржЖржЗ) рззрзпрзлрзп рж╕рж╛рж▓рзЗ ржкрзНрж░рждрж┐рж╖рзНржарж┐ржд рж╣ржпрж╝рзЗржЫрж┐рж▓ ржПржмржВ рждрж╛рж░ржкрж░рзЗ ржерзЗржХрзЗржЗ ржПржЯрж┐ ржкрж╛ржХрж┐рж╕рзНрждрж╛ржирзЗрж░ ржЕрж░рзНржержирзАрждрж┐рж░ ржкрж░рж┐рж╖рзЗржмрж╛ ржжрж┐ржЪрзНржЫрзЗ ржПржмржВ ржжрзЗрж╢ржЯрж┐рж░ ржЙржирзНржиржпрж╝ржи ржУ ржЕржЧрзНрж░ржЧрждрж┐рждрзЗ ржЕржмржжрж╛ржи рж░рж╛ржЦржЫрзЗред ржХрзЗрж╕рж┐ржкрж┐ржЖржЗ ржмрзНржпржХрзНрждрж┐ржЧржд ржХрзЛржорзНржкрж╛ржирж┐ржЧрзБрж▓рзЛржХрзЗ рж╕ржорж░рзНржержи ржУ рж╕рзЗржмрж╛ ржкрзНрж░ржжрж╛ржи ржПржмржВ рж╕ржорж╕рзНржпрж╛рж░ рж╕ржорж╛ржзрж╛ржи ржХрж░рждрзЗ ржЪрзЗрж╖рзНржЯрж╛ ржХрж░рзЗред ржПржХржЯрж┐ рж╕ржВрж╕рзНржерж╛ рж╣рж┐рж╕рзЗржмрзЗ, ржПржЯрж┐ рж╕ржВржмрж╛ржж ржорж╛ржзрзНржпржорзЗрж░ рждрзИрж░рж┐ ржмрж┐ржмрзГрждрж┐ ржПржмржВ ржХрж░рж╛ржЪрж┐ ржУ ржкрж╛ржХрж┐рж╕рзНрждрж╛ржирзЗрж░ ржоржзрзНржпрзЗ ржмрж░рзНрждржорж╛ржи ржЕрж░рзНржержирзИрждрж┐ржХ ржУ ржЖрж░рзНржерж┐ржХ ржмрж┐рж╖ржпрж╝ржЧрзБрж▓рзЛрж░ ржЙржкрж░ ржорждрж╛ржоржд ржкрзНрж░ржХрж╛рж╢ ржХрж░рзЗред ржХрж░рж╛ржЪрж┐ ржмрж╛ржгрж┐ржЬрзНржп ржУ рж╢рж┐рж▓рзНржкрзЗрж░ ржЪрзЗржорзНржмрж╛рж░ рж╣рж▓рзЛ ржжрзЗрж╢ржЯрж┐рж░ ржПржХржЯрж┐ ржкрзНрж░ржзрж╛ржи ржЪрзЗржорзНржмрж╛рж░ред ржПржЯрж┐ ржжрзЗрж╢рзЗрж░ рж╢рж┐рж▓рзНржк, ржмрж╛ржгрж┐ржЬрзНржпрж┐ржХ ржУ ржЕрж░рзНржержирзИрждрж┐ржХ ржХрж░рзНржоржХрж╛ржирзНржбрзЗрж░ ржорзВрж▓ржзрж╛рж░рж╛рж░ ржкрзНрж░рждрж┐ржирж┐ржзрж┐рждрзНржм ржХрж░рзЗ ржерж╛ржХрзЗред ржПржЯрж┐ рззрзпрзлрзп рж╕рж╛рж▓рзЗ ржкрж╛ржХрж┐рж╕рзНрждрж╛ржи ржорж╛рж░рзНржЪрзЗржирзНржЯрж╕ ржПрж╕рзЛрж╕рж┐ржпрж╝рзЗрж╢ржи, ржмрж╛ржпрж╝рж╛рж░рж╕ ржЕрзНржпрж╛ржирзНржб рж╢рж┐ржкрж╛рж░рж╕ ржХржорзНржмрж╛рж░, ржЪрзЗржорзНржмрж╛рж░ ржЕржм ржХржорж╛рж░рзНрж╕ ржкрж╛ржХрж┐рж╕рзНрждрж╛ржи ржПржмржВ ржЕрж▓ ржкрж╛ржХрж┐рж╕рзНрждрж╛ржи ржЪрзЗржорзНржмрж╛рж░ ржЕржл ржХржорж╛рж░рзНрж╕ ржЕрзНржпрж╛ржирзНржб ржЗржирзНржбрж╛рж╕рзНржЯрзНрж░рж┐ ржирж╛ржорзЗ ржЪрж╛рж░ржЯрж┐ ржмрж╛ржгрж┐ржЬрзНржп рж╕ржВрж╕рзНржерж╛рж░ рж╕ржоржирзНржмржпрж╝рзЗ ржЧржарж┐ржд рж╣ржпрж╝рзЗржЫрж┐рж▓ред[рзк] ржПржЯрж┐ рззрзпрзмрзз рж╕рж╛рж▓рзЗ ржЯрзНрж░рзЗржб ржЕрж░рзНржЧрж╛ржирж╛ржЗржЬрзЗрж╢ржи ржЕрж░рзНржбрж┐ржирзНржпрж╛ржирзНрж╕рзЗрж░ ржЕржзрзАржирзЗ ржирж┐ржмржирзНржзрж┐ржд рж╣ржпрж╝рзЗржЫрж┐рж▓, ржпрж╛ ржжрзЗрж╢рзЗ ржЯрзНрж░рзЗржб рж╕ржВрж╕рзНржерж╛рж░ ржХрж╛ржЬржХрзЗ ржирж┐ржпрж╝ржирзНрждрзНрж░ржг ржХрж░рзЗред ржЪрзЗржорзНржмрж╛рж░ ржПржмржВ ржПрж░ ржнржмржирзЗрж░ ржЗрждрж┐рж╣рж╛рж╕рзЗрж░ рж╕рж╛ржерзЗ ржорж╣рж╛рждрзНржорж╛ ржЧрж╛ржирзНржзрзА рж╕ржорзНржкрж░рзНржХрж┐ржд, ржпрж┐ржирж┐ рззрзпрзкрзй рж╕рж╛рж▓рзЗрж░ рзоржЗ ржЬрзБрж▓рж╛ржЗ, ржХрж░рж╛ржЪрж┐ ржЗржирзНржбрж┐ржпрж╝рж╛ржи ржорж╛рж░рзНржЪрзЗржирзНржЯ ржЕрзНржпрж╛рж╕рзЛрж╕рж┐ржпрж╝рзЗрж╢ржирзЗрж░ ржнрж┐рждрзНрждрж┐ ржкрзНрж░рж╕рзНрждрж░ рж╕рзНржерж╛ржкржи ржХрж░рзЗржЫрж┐рж▓рзЗржиред ржПржЯрж┐ ржкрж╛ржХрж┐рж╕рзНрждрж╛ржирзЗрж░ ржПржХржЯрж┐ ржРрждрж┐рж╣рж╛рж╕рж┐ржХ рж╕рзНржорзГрждрж┐рж╕рзНрждржорзНржнред</td>\n      <td>ржХрзЛржиржЯрж┐ ржжрзЗрж╢рзЗ ржЯрзНрж░рзЗржб рж╕ржВрж╕рзНржерж╛рж░ ржХрж╛ржЬржХрзЗ ржирж┐ржпрж╝ржирзНрждрзНрж░ржг ржХрж░рзЗ ?</td>\n      <td>{'answer_start': [793, 793], 'text': ['ржЯрзНрж░рзЗржб ржЕрж░рзНржЧрж╛ржирж╛ржЗржЬрзЗрж╢ржи ржЕрж░рзНржбрж┐ржирзНржпрж╛ржирзНрж╕', 'ржЯрзНрж░рзЗржб ржЕрж░рзНржЧрж╛ржирж╛ржЗржЬрзЗрж╢ржи ржЕрж░рзНржбрж┐ржирзНржпрж╛ржирзНрж╕рзЗрж░']}</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Preprocessing the training data","metadata":{"id":"n9qywopnIrJH"}},{"cell_type":"markdown","source":"Before we can feed those texts to our model, we need to preprocess them. This is done by a ЁЯдЧ Transformers `Tokenizer` which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model requires.\n\nTo do all of this, we instantiate our tokenizer with the `AutoTokenizer.from_pretrained` method, which will ensure:\n\n- we get a tokenizer that corresponds to the model architecture we want to use,\n- we download the vocabulary used when pretraining this specific checkpoint.\n\nThat vocabulary will be cached, so it's not downloaded again the next time we run the cell.","metadata":{"id":"YVx71GdAIrJH"}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"id":"eXNLu_-nIrJI","execution":{"iopub.status.busy":"2024-06-12T15:28:42.074251Z","iopub.execute_input":"2024-06-12T15:28:42.074610Z","iopub.status.idle":"2024-06-12T15:28:44.905234Z","shell.execute_reply.started":"2024-06-12T15:28:42.074581Z","shell.execute_reply":"2024-06-12T15:28:44.904171Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d616ca0349d44dbb4a865f734c39b8e"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"405453c585e447a7a76b9f982883ec88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0806862ed144469830f3e3602d6513e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84f79b8b5d67410e9789372ea6948c11"}},"metadata":{}}]},{"cell_type":"markdown","source":"The following assertion ensures that our tokenizer is a fast tokenizers (backed by Rust) from the ЁЯдЧ Tokenizers library. Those fast tokenizers are available for almost all models, and we will need some of the special features they have for our preprocessing.","metadata":{"id":"Vl6IidfdIrJK"}},{"cell_type":"code","source":"import transformers\nassert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)","metadata":{"id":"tOaNREDfw2D1","execution":{"iopub.status.busy":"2024-06-12T15:28:45.008446Z","iopub.execute_input":"2024-06-12T15:28:45.008830Z","iopub.status.idle":"2024-06-12T15:28:45.013636Z","shell.execute_reply.started":"2024-06-12T15:28:45.008797Z","shell.execute_reply":"2024-06-12T15:28:45.012565Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"You can check which type of models have a fast tokenizer available and which don't on the [big table of models](https://huggingface.co/transformers/index.html#bigtable).","metadata":{"id":"21lBgET6w2D1"}},{"cell_type":"markdown","source":"You can directly call this tokenizer on two sentences (one for the answer, one for the context):","metadata":{"id":"rowT4iCLIrJK"}},{"cell_type":"code","source":"max_length = 384 # The maximum length of a feature (question and context)\ndoc_stride = 128 # The authorized overlap between two part of the context when splitting it is needed.","metadata":{"id":"4P0uKYRuw2D1","execution":{"iopub.status.busy":"2024-06-12T15:28:47.842480Z","iopub.execute_input":"2024-06-12T15:28:47.842846Z","iopub.status.idle":"2024-06-12T15:28:47.847209Z","shell.execute_reply.started":"2024-06-12T15:28:47.842815Z","shell.execute_reply":"2024-06-12T15:28:47.846159Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Note that we never want to truncate the question, only the context, else the `only_second` truncation picked. Now, our tokenizer can automatically return us a list of features capped by a certain maximum length, with the overlap we talked above, we just have to tell it with `return_overflowing_tokens=True` and by passing the stride:","metadata":{"id":"EX2DHM0Bw2D9"}},{"cell_type":"markdown","source":"Now we don't have one list of `input_ids`, but several:","metadata":{"id":"kG9D9IXzw2D9"}},{"cell_type":"markdown","source":"And if we decode them, we can see the overlap:","metadata":{"id":"ZZCm44MZw2D9"}},{"cell_type":"markdown","source":"Now this will give us some work to properly treat the answers: we need to find in which of those features the answer actually is, and where exactly in that feature. The models we will use require the start and end positions of these answers in the tokens, so we will also need to to map parts of the original context to some tokens. Thankfully, the tokenizer we're using can help us with that by returning an `offset_mapping`:","metadata":{"id":"N9NESL_dw2D-"}},{"cell_type":"markdown","source":"So we can use this mapping to find the position of the start and end tokens of our answer in a given feature. We just have to distinguish which parts of the offsets correspond to the question and which part correspond to the context, this is where the `sequence_ids` method of our `tokenized_example` can be useful:","metadata":{"id":"BwM6CAaMw2D-"}},{"cell_type":"code","source":"sequence_ids = tokenized_example.sequence_ids()\nprint(sequence_ids)","metadata":{"id":"WCZgd3w4w2D-","outputId":"7e8a06fc-59f1-4292-c68a-4a781b31306b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And we can double check that it is indeed the theoretical answer:","metadata":{"id":"Tb8YZi6Nw2D-"}},{"cell_type":"markdown","source":"For this notebook to work with any kind of models, we need to account for the special case where the model expects padding on the left (in which case we switch the order of the question and the context):","metadata":{"id":"nQnfldBsw2D-"}},{"cell_type":"code","source":"pad_on_right = tokenizer.padding_side == \"right\"","metadata":{"id":"lLPTEjfYw2D-","execution":{"iopub.status.busy":"2024-06-12T15:28:51.089389Z","iopub.execute_input":"2024-06-12T15:28:51.089776Z","iopub.status.idle":"2024-06-12T15:28:51.094146Z","shell.execute_reply.started":"2024-06-12T15:28:51.089746Z","shell.execute_reply":"2024-06-12T15:28:51.093154Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"Now let's put everything together in one function we will apply to our training set. In the case of impossible answers (the answer is in another feature given by an example with a long context), we set the cls index for both the start and end position. We could also simply discard those examples from the training set if the flag `allow_impossible_answers` is `False`. Since the preprocessing is already complex enough as it is, we've kept is simple for this part.","metadata":{"id":"iRlloYl_w2D_"}},{"cell_type":"code","source":"def prepare_train_features(examples):\n    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n    # left whitespace\n    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n\n    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n    # in one example possible giving several features when a context is long, each of those features having a\n    # context that overlaps a bit the context of the previous feature.\n    tokenized_examples = tokenizer(\n        examples[\"question\" if pad_on_right else \"context\"],\n        examples[\"context\" if pad_on_right else \"question\"],\n        truncation=\"only_second\" if pad_on_right else \"only_first\",\n        max_length=max_length,\n        stride=doc_stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    # Since one example might give us several features if it has a long context, we need a map from a feature to\n    # its corresponding example. This key gives us just that.\n    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n    # The offset mappings will give us a map from token to character position in the original context. This will\n    # help us compute the start_positions and end_positions.\n    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n\n    # Let's label those examples!\n    tokenized_examples[\"start_positions\"] = []\n    tokenized_examples[\"end_positions\"] = []\n\n    for i, offsets in enumerate(offset_mapping):\n        # We will label impossible answers with the index of the CLS token.\n        input_ids = tokenized_examples[\"input_ids\"][i]\n        cls_index = input_ids.index(tokenizer.cls_token_id)\n\n        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n        sequence_ids = tokenized_examples.sequence_ids(i)\n\n        # One example can give several spans, this is the index of the example containing this span of text.\n        sample_index = sample_mapping[i]\n        answers = examples[\"answers\"][sample_index]\n        # If no answers are given, set the cls_index as answer.\n        if len(answers[\"answer_start\"]) == 0:\n            tokenized_examples[\"start_positions\"].append(cls_index)\n            tokenized_examples[\"end_positions\"].append(cls_index)\n        else:\n            # Start/end character index of the answer in the text.\n            start_char = answers[\"answer_start\"][0]\n            end_char = start_char + len(answers[\"text\"][0])\n\n            # Start token index of the current span in the text.\n            token_start_index = 0\n            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n                token_start_index += 1\n\n            # End token index of the current span in the text.\n            token_end_index = len(input_ids) - 1\n            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n                token_end_index -= 1\n\n            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n                tokenized_examples[\"start_positions\"].append(cls_index)\n                tokenized_examples[\"end_positions\"].append(cls_index)\n            else:\n                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n                # Note: we could go after the last offset if the answer is the last word (edge case).\n                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n                    token_start_index += 1\n                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n                while offsets[token_end_index][1] >= end_char:\n                    token_end_index -= 1\n                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n\n    return tokenized_examples","metadata":{"id":"R5Ou_Vnnw2D_","execution":{"iopub.status.busy":"2024-06-12T15:28:51.612094Z","iopub.execute_input":"2024-06-12T15:28:51.612817Z","iopub.status.idle":"2024-06-12T15:28:51.627534Z","shell.execute_reply.started":"2024-06-12T15:28:51.612783Z","shell.execute_reply":"2024-06-12T15:28:51.626449Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"This function works with one or several examples. In the case of several examples, the tokenizer will return a list of lists for each key:","metadata":{"id":"0lm8ozrJIrJR"}},{"cell_type":"markdown","source":"To apply this function on all the sentences (or pairs of sentences) in our dataset, we just use the `map` method of our `dataset` object we created earlier. This will apply the function on all the elements of all the splits in `dataset`, so our training, validation and testing data will be preprocessed in one single command. Since our preprocessing changes the number of samples, we need to remove the old columns when applying it.","metadata":{"id":"zS-6iXTkIrJT"}},{"cell_type":"code","source":"tokenized_datasets = datasets.map(prepare_train_features, batched=True, remove_columns=datasets[\"train\"].column_names)","metadata":{"id":"DDtsaJeVIrJT","outputId":"aa4734bf-4ef5-4437-9948-2c16363da719","execution":{"iopub.status.busy":"2024-06-12T15:28:53.500635Z","iopub.execute_input":"2024-06-12T15:28:53.501363Z","iopub.status.idle":"2024-06-12T15:29:12.228974Z","shell.execute_reply.started":"2024-06-12T15:28:53.501321Z","shell.execute_reply":"2024-06-12T15:29:12.227867Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9565 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd69b84f86ec46cf8d3e4ee460a09ad5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1182 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da79722b45854d029cf3e647769bd5da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1172 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ea3d500def1495db141cda360667f6b"}},"metadata":{}}]},{"cell_type":"markdown","source":"Even better, the results are automatically cached by the ЁЯдЧ Datasets library to avoid spending time on this step the next time you run your notebook. The ЁЯдЧ Datasets library is normally smart enough to detect when the function you pass to map has changed (and thus requires to not use the cache data). For instance, it will properly detect if you change the task in the first cell and rerun the notebook. ЁЯдЧ Datasets warns you when it uses cached files, you can pass `load_from_cache_file=False` in the call to `map` to not use the cached files and force the preprocessing to be applied again.\n\nNote that we passed `batched=True` to encode the texts by batches together. This is to leverage the full benefit of the fast tokenizer we loaded earlier, which will use multi-threading to treat the texts in a batch concurrently.","metadata":{"id":"voWiw8C7IrJV"}},{"cell_type":"markdown","source":"## Fine-tuning the model","metadata":{"id":"545PP3o8IrJV"}},{"cell_type":"markdown","source":"Now that our data is ready for training, we can download the pretrained model and fine-tune it. Since our task is question answering, we use the `AutoModelForQuestionAnswering` class. Like with the tokenizer, the `from_pretrained` method will download and cache the model for us:","metadata":{"id":"FBiW8UpKIrJW"}},{"cell_type":"code","source":"from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer\n\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)","metadata":{"id":"TlqNaB8jIrJW","outputId":"84916cf3-6e6c-47f3-d081-032ec30a4132","execution":{"iopub.status.busy":"2024-06-12T15:29:15.098208Z","iopub.execute_input":"2024-06-12T15:29:15.098706Z","iopub.status.idle":"2024-06-12T15:29:34.199997Z","shell.execute_reply.started":"2024-06-12T15:29:15.098664Z","shell.execute_reply":"2024-06-12T15:29:34.199047Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"2024-06-12 15:29:18.439519: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-12 15:29:18.439633: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-12 15:29:18.578539: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69845bbc28d643cc9164306bc4aab047"}},"metadata":{}},{"name":"stderr","text":"Some weights of XLMRobertaForQuestionAnswering were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The warning is telling us we are throwing away some weights (the `vocab_transform` and `vocab_layer_norm` layers) and randomly initializing some other (the `pre_classifier` and `classifier` layers). This is absolutely normal in this case, because we are removing the head used to pretrain the model on a masked language modeling objective and replacing it with a new head for which we don't have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do.","metadata":{"id":"CczA5lJlIrJX"}},{"cell_type":"markdown","source":"To instantiate a `Trainer`, we will need to define three more things. The most important is the [`TrainingArguments`](https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments), which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional:","metadata":{"id":"_N8urzhyIrJY"}},{"cell_type":"code","source":"model_name = model_checkpoint.split(\"/\")[-1]\nargs = TrainingArguments(\n    f\"{model_name}-finetuned-RQA-confirmation\",\n    evaluation_strategy = \"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    save_strategy=\"no\",\n    push_to_hub=True,\n)","metadata":{"id":"Bliy8zgjIrJY","execution":{"iopub.status.busy":"2024-06-12T15:29:37.644310Z","iopub.execute_input":"2024-06-12T15:29:37.645409Z","iopub.status.idle":"2024-06-12T15:29:37.725517Z","shell.execute_reply.started":"2024-06-12T15:29:37.645371Z","shell.execute_reply":"2024-06-12T15:29:37.724545Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ЁЯдЧ Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Here we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the `batch_size` defined at the top of the notebook and customize the number of epochs for training, as well as the weight decay.\n\nThe last argument to setup everything so we can push the model to the [Hub](https://huggingface.co/models) regularly during training. Remove it if you didn't follow the installation steps at the top of the notebook. If you want to save your model locally in a name that is different than the name of the repository it will be pushed, or if you want to push your model under an organization and not your name space, use the `hub_model_id` argument to set the repo name (it needs to be the full name, including your namespace: for instance `\"sgugger/bert-finetuned-squad\"` or `\"huggingface/bert-finetuned-squad\"`).","metadata":{"id":"km3pGVdTIrJc"}},{"cell_type":"markdown","source":"Then we will need a data collator that will batch our processed examples together, here the default one will work:","metadata":{"id":"I-84Z1Vxw2D_"}},{"cell_type":"code","source":"from transformers import default_data_collator\n\ndata_collator = default_data_collator","metadata":{"id":"-NIrFiIjw2D_","execution":{"iopub.status.busy":"2024-06-12T15:29:40.626658Z","iopub.execute_input":"2024-06-12T15:29:40.627399Z","iopub.status.idle":"2024-06-12T15:29:40.631644Z","shell.execute_reply.started":"2024-06-12T15:29:40.627363Z","shell.execute_reply":"2024-06-12T15:29:40.630627Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"We will evaluate our model and compute metrics in the next section (this is a very long operation, so we will only compute the evaluation loss during training).\n\nThen we just need to pass all of this along with our datasets to the `Trainer`:","metadata":{"id":"rXuFTAzDIrJe"}},{"cell_type":"code","source":"#small_train_dataset = tokenized_datasets[\"train\"].select(range(60000))  # Selecting the first 1000 examples\n\n# Now, you can pass this smaller dataset to the Trainer\ntrainer = Trainer(\n    model,\n    args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n)","metadata":{"id":"imY1oC3SIrJf","execution":{"iopub.status.busy":"2024-06-12T15:29:41.254929Z","iopub.execute_input":"2024-06-12T15:29:41.255791Z","iopub.status.idle":"2024-06-12T15:29:46.230483Z","shell.execute_reply.started":"2024-06-12T15:29:41.255754Z","shell.execute_reply":"2024-06-12T15:29:46.228968Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"We can now finetune our model by just calling the `train` method:","metadata":{"id":"CdzABDVcIrJg"}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"id":"uNx5pyRlIrJh","outputId":"077e661e-d36c-469b-89b8-7ff7f73541ec","execution":{"iopub.status.busy":"2024-06-12T15:29:48.560041Z","iopub.execute_input":"2024-06-12T15:29:48.560432Z","iopub.status.idle":"2024-06-12T16:11:57.932220Z","shell.execute_reply.started":"2024-06-12T15:29:48.560401Z","shell.execute_reply":"2024-06-12T16:11:57.931168Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖┬╖\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240612_152955-faejqwqw</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/iut2024/huggingface/runs/faejqwqw' target=\"_blank\">xlm-roberta-base-finetuned-RQA-confirmation</a></strong> to <a href='https://wandb.ai/iut2024/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/iut2024/huggingface' target=\"_blank\">https://wandb.ai/iut2024/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/iut2024/huggingface/runs/faejqwqw' target=\"_blank\">https://wandb.ai/iut2024/huggingface/runs/faejqwqw</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='3681' max='3681' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [3681/3681 41:43, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.010400</td>\n      <td>0.792556</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.766100</td>\n      <td>0.745149</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.594200</td>\n      <td>0.739113</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=3681, training_loss=0.8744924265999601, metrics={'train_runtime': 2529.019, 'train_samples_per_second': 23.28, 'train_steps_per_second': 1.456, 'total_flos': 1.1537884914624e+16, 'train_loss': 0.8744924265999601, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"Since this training is particularly long, let's save the model just in case we need to restart.","metadata":{"id":"MCbpvHopw2EA"}},{"cell_type":"code","source":"trainer.save_model(\"XLMBERT-RQA-confirmation\")","metadata":{"id":"FM8cWwnvw2EA","execution":{"iopub.status.busy":"2024-06-12T16:12:23.350821Z","iopub.execute_input":"2024-06-12T16:12:23.351264Z","iopub.status.idle":"2024-06-12T16:12:59.654388Z","shell.execute_reply.started":"2024-06-12T16:12:23.351207Z","shell.execute_reply":"2024-06-12T16:12:59.653133Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e51e914eb9fa464d946804400c9966cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e9b850916664c2c9298be23a92a7f46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"events.out.tfevents.1718206188.8cb7b71e7a24.34.0:   0%|          | 0.00/7.59k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11befbfa50b34f9c91178665c3833031"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/5.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25070e00d44144818e86c9083447c625"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Evaluation","metadata":{"id":"L1P5VpM4w2EA"}},{"cell_type":"markdown","source":"Evaluating our model will require a bit more work, as we will need to map the predictions of our model back to parts of the context. The model itself predicts logits for the start and en position of our answers: if we take a batch from our validation datalaoder, here is the output our model gives us:","metadata":{"id":"bmOY1b2Lw2EA"}},{"cell_type":"code","source":"import torch\n\nfor batch in trainer.get_eval_dataloader():\n    break\nbatch = {k: v.to(trainer.args.device) for k, v in batch.items()}\nwith torch.no_grad():\n    output = trainer.model(**batch)\noutput.keys()","metadata":{"id":"0R6UKhL7w2EA","outputId":"2ccaec67-e456-42b0-ce44-4cdcb1c82353","execution":{"iopub.status.busy":"2024-06-12T16:13:25.459476Z","iopub.execute_input":"2024-06-12T16:13:25.459861Z","iopub.status.idle":"2024-06-12T16:13:25.521908Z","shell.execute_reply.started":"2024-06-12T16:13:25.459830Z","shell.execute_reply":"2024-06-12T16:13:25.520793Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"odict_keys(['loss', 'start_logits', 'end_logits'])"},"metadata":{}}]},{"cell_type":"markdown","source":"The output of the model is a dict-like object that contains the loss (since we provided labels), the start and end logits. We won't need the loss for our predictions, let's have a look a the logits:","metadata":{"id":"CefzV1Oqw2EA"}},{"cell_type":"code","source":"output.start_logits.shape, output.end_logits.shape","metadata":{"id":"VETC3NLdw2EA","outputId":"5bade4c5-a3aa-4d7a-a28c-5b14713297d7","execution":{"iopub.status.busy":"2024-06-12T16:13:26.015890Z","iopub.execute_input":"2024-06-12T16:13:26.016311Z","iopub.status.idle":"2024-06-12T16:13:26.025243Z","shell.execute_reply.started":"2024-06-12T16:13:26.016276Z","shell.execute_reply":"2024-06-12T16:13:26.023789Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"(torch.Size([16, 384]), torch.Size([16, 384]))"},"metadata":{}}]},{"cell_type":"markdown","source":"We have one logit for each feature and each token. The most obvious thing to predict an answer for each featyre is to take the index for the maximum of the start logits as a start position and the index of the maximum of the end logits as an end position.","metadata":{"id":"JJnbu47hw2EA"}},{"cell_type":"code","source":"output.start_logits.argmax(dim=-1), output.end_logits.argmax(dim=-1)","metadata":{"id":"h6A7QokVw2EA","outputId":"8cb18000-10f7-40da-980f-4c5d433ba9d5","execution":{"iopub.status.busy":"2024-06-12T16:13:27.209863Z","iopub.execute_input":"2024-06-12T16:13:27.210713Z","iopub.status.idle":"2024-06-12T16:13:27.232195Z","shell.execute_reply.started":"2024-06-12T16:13:27.210677Z","shell.execute_reply":"2024-06-12T16:13:27.230943Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(tensor([123,   0, 159,   0,   0, 186,   0,   0, 204,   0,   0,   0,  33,   0,\n          25,   0], device='cuda:0'),\n tensor([126,   0, 160,   0,   0, 188,   0,   0, 215,   0,   0,   0,  45,   0,\n          26,   0], device='cuda:0'))"},"metadata":{}}]},{"cell_type":"markdown","source":"This will work great in a lot of cases, but what if this prediction gives us something impossible: the start position could be greater than the end position, or point to a span of text in the question instead of the answer. In that case, we might want to look at the second best prediction to see if it gives a possible answer and select that instead.\n\nHowever, picking the second best answer is not as easy as picking the best one: is it the second best index in the start logits with the best index in the end logits? Or the best index in the start logits with the second best index in the end logits? And if that second best answer is not possible either, it gets even trickier for the third best answer.\n\n\nTo classify our answers, we will use the score obtained by adding the start and end logits. We won't try to order all the possible answers and limit ourselves to with a hyper-parameter we call `n_best_size`. We'll pick the best indices in the start and end logits and gather all the answers this predicts. After checking if each one is valid, we will sort them by their score and keep the best one. Here is how we would do this on the first feature in the batch:","metadata":{"id":"uJQJZJYRw2EA"}},{"cell_type":"code","source":"n_best_size = 20","metadata":{"id":"9ffQ5ca_w2EA","execution":{"iopub.status.busy":"2024-06-12T16:13:29.213018Z","iopub.execute_input":"2024-06-12T16:13:29.213449Z","iopub.status.idle":"2024-06-12T16:13:29.219740Z","shell.execute_reply.started":"2024-06-12T16:13:29.213414Z","shell.execute_reply":"2024-06-12T16:13:29.218631Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nstart_logits = output.start_logits[0].cpu().numpy()\nend_logits = output.end_logits[0].cpu().numpy()\n# Gather the indices the best start/end logits:\nstart_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\nend_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\nvalid_answers = []\nfor start_index in start_indexes:\n    for end_index in end_indexes:\n        if start_index <= end_index: # We need to refine that test to check the answer is inside the context\n            valid_answers.append(\n                {\n                    \"score\": start_logits[start_index] + end_logits[end_index],\n                    \"text\": \"\" # We need to find a way to get back the original substring corresponding to the answer in the context\n                }\n            )","metadata":{"id":"b-adKL89w2EA","execution":{"iopub.status.busy":"2024-06-12T16:13:29.808575Z","iopub.execute_input":"2024-06-12T16:13:29.808933Z","iopub.status.idle":"2024-06-12T16:13:29.820635Z","shell.execute_reply.started":"2024-06-12T16:13:29.808901Z","shell.execute_reply":"2024-06-12T16:13:29.819755Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":"And then we can sort the `valid_answers` according to their `score` and only keep the best one. The only point left is how to check a given span is inside the context (and not the question) and how to get back the text inside. To do this, we need to add two things to our validation features:\n- the ID of the example that generated the feature (since each example can generate several features, as seen before);\n- the offset mapping that will give us a map from token indices to character positions in the context.\n\nThat's why we will re-process the validation set with the following function, slightly different from `prepare_train_features`:","metadata":{"id":"N-pXkEb3w2EA"}},{"cell_type":"code","source":"def prepare_validation_features(examples):\n    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n    # left whitespace\n    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n\n    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n    # in one example possible giving several features when a context is long, each of those features having a\n    # context that overlaps a bit the context of the previous feature.\n    tokenized_examples = tokenizer(\n        examples[\"question\" if pad_on_right else \"context\"],\n        examples[\"context\" if pad_on_right else \"question\"],\n        truncation=\"only_second\" if pad_on_right else \"only_first\",\n        max_length=max_length,\n        stride=doc_stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    # Since one example might give us several features if it has a long context, we need a map from a feature to\n    # its corresponding example. This key gives us just that.\n    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n\n    # We keep the example_id that gave us this feature and we will store the offset mappings.\n    tokenized_examples[\"example_id\"] = []\n\n    for i in range(len(tokenized_examples[\"input_ids\"])):\n        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n        sequence_ids = tokenized_examples.sequence_ids(i)\n        context_index = 1 if pad_on_right else 0\n\n        # One example can give several spans, this is the index of the example containing this span of text.\n        sample_index = sample_mapping[i]\n        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n\n        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n        # position is part of the context or not.\n        tokenized_examples[\"offset_mapping\"][i] = [\n            (o if sequence_ids[k] == context_index else None)\n            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n        ]\n\n    return tokenized_examples","metadata":{"id":"RPszZgmew2EA","execution":{"iopub.status.busy":"2024-06-12T16:13:30.555971Z","iopub.execute_input":"2024-06-12T16:13:30.556732Z","iopub.status.idle":"2024-06-12T16:13:30.567294Z","shell.execute_reply.started":"2024-06-12T16:13:30.556697Z","shell.execute_reply":"2024-06-12T16:13:30.566272Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"And like before, we can apply that function to our validation set easily:","metadata":{"id":"ovv2b2CEw2EB"}},{"cell_type":"code","source":"validation_features = datasets[\"validation\"].map(\n    prepare_validation_features,\n    batched=True,\n    remove_columns=datasets[\"validation\"].column_names\n)","metadata":{"id":"kfzv5g0ww2EB","outputId":"93fad142-d7ec-4a2f-893d-b909ca7096ea","execution":{"iopub.status.busy":"2024-06-12T16:13:31.428287Z","iopub.execute_input":"2024-06-12T16:13:31.429007Z","iopub.status.idle":"2024-06-12T16:13:34.260686Z","shell.execute_reply.started":"2024-06-12T16:13:31.428971Z","shell.execute_reply":"2024-06-12T16:13:34.259479Z"},"trusted":true},"execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1182 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a963ec3130404e0fab0df999d3b822ad"}},"metadata":{}}]},{"cell_type":"markdown","source":"Now we can grab the predictions for all features by using the `Trainer.predict` method:","metadata":{"id":"sGpSTWzgw2EB"}},{"cell_type":"code","source":"raw_predictions = trainer.predict(validation_features)","metadata":{"id":"Et4sZmqQw2EB","outputId":"98a3ca75-e328-4691-d8b6-a598d4298404","execution":{"iopub.status.busy":"2024-06-12T16:13:36.226837Z","iopub.execute_input":"2024-06-12T16:13:36.227296Z","iopub.status.idle":"2024-06-12T16:14:09.725191Z","shell.execute_reply.started":"2024-06-12T16:13:36.227251Z","shell.execute_reply":"2024-06-12T16:14:09.724171Z"},"trusted":true},"execution_count":30,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"markdown","source":"The `Trainer` *hides* the columns that are not used by the model (here `example_id` and `offset_mapping` which we will need for our post-processing), so we set them back:","metadata":{"id":"BC1T0lh3w2EB"}},{"cell_type":"code","source":"validation_features.set_format(type=validation_features.format[\"type\"], columns=list(validation_features.features.keys()))","metadata":{"id":"2Z_X9fTGw2EB","execution":{"iopub.status.busy":"2024-06-12T16:14:11.109050Z","iopub.execute_input":"2024-06-12T16:14:11.110031Z","iopub.status.idle":"2024-06-12T16:14:11.118055Z","shell.execute_reply.started":"2024-06-12T16:14:11.109995Z","shell.execute_reply":"2024-06-12T16:14:11.116857Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"We can now refine the test we had before: since we set `None` in the offset mappings when it corresponds to a part of the question, it's easy to check if an answer is fully inside the context. We also eliminate very long answers from our considerations (with an hyper-parameter we can tune)","metadata":{"id":"Ke82o_Faw2EB"}},{"cell_type":"code","source":"max_answer_length = 15","metadata":{"id":"O486GLyuw2EB","execution":{"iopub.status.busy":"2024-06-12T16:14:12.594675Z","iopub.execute_input":"2024-06-12T16:14:12.595670Z","iopub.status.idle":"2024-06-12T16:14:12.600850Z","shell.execute_reply.started":"2024-06-12T16:14:12.595633Z","shell.execute_reply":"2024-06-12T16:14:12.599625Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"start_logits = output.start_logits[0].cpu().numpy()\nend_logits = output.end_logits[0].cpu().numpy()\noffset_mapping = validation_features[0][\"offset_mapping\"]\n# The first feature comes from the first example. For the more general case, we will need to be match the example_id to\n# an example index\ncontext = datasets[\"validation\"][0][\"context\"]\n\n# Gather the indices the best start/end logits:\nstart_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\nend_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\nvalid_answers = []\nfor start_index in start_indexes:\n    for end_index in end_indexes:\n        # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n        # to part of the input_ids that are not in the context.\n        if (\n            start_index >= len(offset_mapping)\n            or end_index >= len(offset_mapping)\n            or offset_mapping[start_index] is None\n            or offset_mapping[end_index] is None\n        ):\n            continue\n        # Don't consider answers with a length that is either < 0 or > max_answer_length.\n        if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n            continue\n        if start_index <= end_index: # We need to refine that test to check the answer is inside the context\n            start_char = offset_mapping[start_index][0]\n            end_char = offset_mapping[end_index][1]\n            valid_answers.append(\n                {\n                    \"score\": start_logits[start_index] + end_logits[end_index],\n                    \"text\": context[start_char: end_char]\n                }\n            )\n\nvalid_answers = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[:n_best_size]\nvalid_answers","metadata":{"id":"Nd4-9OwVw2EB","outputId":"8e510576-1b5b-4999-d7c0-77b524f6b91d","execution":{"iopub.status.busy":"2024-06-12T16:14:13.911922Z","iopub.execute_input":"2024-06-12T16:14:13.912879Z","iopub.status.idle":"2024-06-12T16:14:13.937575Z","shell.execute_reply.started":"2024-06-12T16:14:13.912831Z","shell.execute_reply":"2024-06-12T16:14:13.935717Z"},"trusted":true},"execution_count":33,"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"[{'score': 13.580887, 'text': 'рж▓рзНржпрзБржнрж░'},\n {'score': 12.440959, 'text': 'рж▓рзНржпрзБржнрж░ ржЬрж╛ржжрзБржШрж░рзЗ'},\n {'score': 11.779528, 'text': 'рж▓рзНржпрзБржнрж░ ржЬрж╛'},\n {'score': 11.646145, 'text': 'рж▓рзНржпрзБржнрж░ ржЬрж╛ржжрзБржШрж░'},\n {'score': 11.4228115, 'text': 'рж▓рзНржпрзБржнрж░ ржЬрж╛ржжрзБржШрж░рзЗ ржжрзБржЯрж┐'},\n {'score': 9.310792, 'text': 'рж▓рзНржпрзБржнрж░ ржЬрж╛ржжрзБ'},\n {'score': 8.682725, 'text': 'рж▓рзНржпрзБржнрж░ ржЬрж╛ржжрзБржШрж░рзЗ ржжрзБржЯрж┐ рж╕'},\n {'score': 8.25496, 'text': 'рж▓рзНржпрзБржн'},\n {'score': 7.5626016, 'text': 'рж▓'},\n {'score': 7.3709507, 'text': 'ред рж▓рзНржпрзБржнрж░'},\n {'score': 7.074316, 'text': 'ржжрзБржЯрж┐'},\n {'score': 6.3805876, 'text': 'рж▓рзНржпрзБржнрж░ ржЬрж╛ржжрзБржШрж░рзЗ ржжрзБржЯрж┐ рж╕рж╛рж░'},\n {'score': 6.2310233, 'text': 'ред рж▓рзНржпрзБржнрж░ ржЬрж╛ржжрзБржШрж░рзЗ'},\n {'score': 5.771965, 'text': 'рж▓рзНржпрзБржнрж░ ржЬрж╛ржжрзБржШрж░рзЗ ржжрзБржЯрж┐ рж╕рж╛рж░ржЧржирж┐ржХ'},\n {'score': 5.7438116, 'text': 'рж▓рзНржпрзБ'},\n {'score': 5.5695915, 'text': 'ред рж▓рзНржпрзБржнрж░ ржЬрж╛'},\n {'score': 5.436209, 'text': 'ред рж▓рзНржпрзБржнрж░ ржЬрж╛ржжрзБржШрж░'},\n {'score': 5.4225903, 'text': 'рзНржпрзБржнрж░'},\n {'score': 5.290488, 'text': 'рж▓рзНржпрзБржнрж░ ржЬрж╛ржжрзБржШрж░рзЗ ржжрзБржЯрж┐ рж╕рж╛рж░ржЧржирж┐ржХ ржмрж┐ржЬржпрж╝'},\n {'score': 5.2128763, 'text': 'ред рж▓рзНржпрзБржнрж░ ржЬрж╛ржжрзБржШрж░рзЗ ржжрзБржЯрж┐'}]"},"metadata":{}}]},{"cell_type":"markdown","source":"We can compare to the actual ground-truth answer:","metadata":{"id":"_SzL9tUWw2EB"}},{"cell_type":"code","source":"datasets[\"validation\"][0][\"answers\"]","metadata":{"id":"omSsQ4Pjw2EB","outputId":"4753889e-47ad-45a7-c07a-7e6dbeffcf1f","execution":{"iopub.status.busy":"2024-06-12T16:14:15.949684Z","iopub.execute_input":"2024-06-12T16:14:15.950560Z","iopub.status.idle":"2024-06-12T16:14:15.958699Z","shell.execute_reply.started":"2024-06-12T16:14:15.950523Z","shell.execute_reply":"2024-06-12T16:14:15.957143Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"{'answer_start': [292, 292], 'text': ['рж▓рзНржпрзБржнрж░ ржЬрж╛ржжрзБржШрж░рзЗ', 'рж▓рзНржпрзБржнрж░ ржЬрж╛ржжрзБржШрж░рзЗ']}"},"metadata":{}}]},{"cell_type":"markdown","source":"Our model picked the right as the most likely answer!\n\nAs we mentioned in the code above, this was easy on the first feature because we knew it comes from the first example. For the other features, we will need a map between examples and their corresponding features. Also, since one example can give several features, we will need to gather together all the answers in all the features generated by a given example, then pick the best one. The following code builds a map from example index to its corresponding features indices:","metadata":{"id":"XG5kWsMGw2EB"}},{"cell_type":"code","source":"import collections\n\nexamples = datasets[\"validation\"]\nfeatures = validation_features\n\nexample_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\nfeatures_per_example = collections.defaultdict(list)\nfor i, feature in enumerate(features):\n    features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)","metadata":{"id":"7suYtpYjw2EB","execution":{"iopub.status.busy":"2024-06-12T16:14:18.565914Z","iopub.execute_input":"2024-06-12T16:14:18.566337Z","iopub.status.idle":"2024-06-12T16:14:23.531634Z","shell.execute_reply.started":"2024-06-12T16:14:18.566302Z","shell.execute_reply":"2024-06-12T16:14:23.530388Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"We're almost ready for our post-processing function. The last bit to deal with is the impossible answer (when `squad_v2 = True`). The code above only keeps answers that are inside the context, we need to also grab the score for the impossible answer (which has start and end indices corresponding to the index of the CLS token). When one example gives several features, we have to predict the impossible answer when all the features give a high score to the impossible answer (since one feature could predict the impossible answer just because the answer isn't in the part of the context it has access too), which is why the score of the impossible answer for one example is the *minimum* of the scores for the impossible answer in each feature generated by the example.\n\nWe then predict the impossible answer when that score is greater than the score of the best non-impossible answer. All combined together, this gives us this post-processing function:","metadata":{"id":"hcB5GyLPw2EB"}},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\ndef postprocess_qa_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 30):\n    all_start_logits, all_end_logits = raw_predictions\n    # Build a map example to its corresponding features.\n    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n    features_per_example = collections.defaultdict(list)\n    for i, feature in enumerate(features):\n        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n\n    # The dictionaries we have to fill.\n    predictions = collections.OrderedDict()\n\n    # Logging.\n    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n\n    # Let's loop over all the examples!\n    for example_index, example in enumerate(tqdm(examples)):\n        # Those are the indices of the features associated to the current example.\n        feature_indices = features_per_example[example_index]\n\n        min_null_score = None # Only used if squad_v2 is True.\n        valid_answers = []\n\n        context = example[\"context\"]\n        # Looping through all the features associated to the current example.\n        for feature_index in feature_indices:\n            # We grab the predictions of the model for this feature.\n            start_logits = all_start_logits[feature_index]\n            end_logits = all_end_logits[feature_index]\n            # This is what will allow us to map some the positions in our logits to span of texts in the original\n            # context.\n            offset_mapping = features[feature_index][\"offset_mapping\"]\n\n            # Update minimum null prediction.\n            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n            if min_null_score is None or min_null_score < feature_null_score:\n                min_null_score = feature_null_score\n\n            # Go through all possibilities for the `n_best_size` greater start and end logits.\n            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n            for start_index in start_indexes:\n                for end_index in end_indexes:\n                    # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n                    # to part of the input_ids that are not in the context.\n                    if (\n                        start_index >= len(offset_mapping)\n                        or end_index >= len(offset_mapping)\n                        or offset_mapping[start_index] is None\n                        or offset_mapping[end_index] is None\n                    ):\n                        continue\n                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n                        continue\n\n                    start_char = offset_mapping[start_index][0]\n                    end_char = offset_mapping[end_index][1]\n                    valid_answers.append(\n                        {\n                            \"score\": start_logits[start_index] + end_logits[end_index],\n                            \"text\": context[start_char: end_char]\n                        }\n                    )\n\n        if len(valid_answers) > 0:\n            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n        else:\n            # In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid\n            # failure.\n            best_answer = {\"text\": \"\", \"score\": 0.0}\n\n        # Let's pick our final answer: the best one or the null answer (only for squad_v2)\n        if not squad_v2:\n            predictions[example[\"id\"]] = best_answer[\"text\"]\n        else:\n            answer = best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else \"\"\n            predictions[example[\"id\"]] = answer\n\n    return predictions","metadata":{"id":"ASgyIP4Rw2EB","execution":{"iopub.status.busy":"2024-06-12T16:14:26.102185Z","iopub.execute_input":"2024-06-12T16:14:26.102840Z","iopub.status.idle":"2024-06-12T16:14:26.121815Z","shell.execute_reply.started":"2024-06-12T16:14:26.102811Z","shell.execute_reply":"2024-06-12T16:14:26.120727Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"And we can apply our post-processing function to our raw predictions:","metadata":{"id":"4sSSQRBlw2EC"}},{"cell_type":"code","source":"final_predictions = postprocess_qa_predictions(datasets[\"validation\"], validation_features, raw_predictions.predictions)","metadata":{"id":"p593YBskw2EC","outputId":"5a280295-d51a-42b2-cef2-4f5e119a979e","execution":{"iopub.status.busy":"2024-06-12T16:14:26.752044Z","iopub.execute_input":"2024-06-12T16:14:26.752922Z","iopub.status.idle":"2024-06-12T16:14:44.340924Z","shell.execute_reply.started":"2024-06-12T16:14:26.752886Z","shell.execute_reply":"2024-06-12T16:14:44.339684Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Post-processing 1182 example predictions split into 2469 features.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1182 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8c560adf380432e9e4e33d5977dfedd"}},"metadata":{}}]},{"cell_type":"markdown","source":"Then we can load the metric from the datasets library.","metadata":{"id":"NanNCGPVw2EC"}},{"cell_type":"code","source":"\n!pip install evaluate -q","metadata":{"execution":{"iopub.status.busy":"2024-06-12T16:14:48.912187Z","iopub.execute_input":"2024-06-12T16:14:48.912607Z","iopub.status.idle":"2024-06-12T16:15:03.051870Z","shell.execute_reply.started":"2024-06-12T16:14:48.912571Z","shell.execute_reply":"2024-06-12T16:15:03.050547Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"squad_v2\")","metadata":{"id":"SxSZEwIkw2EC","execution":{"iopub.status.busy":"2024-06-12T16:15:04.420277Z","iopub.execute_input":"2024-06-12T16:15:04.420700Z","iopub.status.idle":"2024-06-12T16:15:05.308889Z","shell.execute_reply.started":"2024-06-12T16:15:04.420663Z","shell.execute_reply":"2024-06-12T16:15:05.307728Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfe13c6919774eb489e8405021dd0e93"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/11.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15b8fe484a7444d4885bef6fd67aecda"}},"metadata":{}}]},{"cell_type":"code","source":"theoretical_answers = [\n    {\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in datasets[\"validation\"]\n]","metadata":{"execution":{"iopub.status.busy":"2024-06-12T16:15:05.310775Z","iopub.execute_input":"2024-06-12T16:15:05.311201Z","iopub.status.idle":"2024-06-12T16:15:05.453379Z","shell.execute_reply.started":"2024-06-12T16:15:05.311164Z","shell.execute_reply":"2024-06-12T16:15:05.452189Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":" formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in final_predictions.items()]\nformatted_predictions = [{\"id\": k, \"prediction_text\": v, \"no_answer_probability\": 0.0} for k, v in final_predictions.items()]\n     ","metadata":{"execution":{"iopub.status.busy":"2024-06-12T16:15:07.437945Z","iopub.execute_input":"2024-06-12T16:15:07.438770Z","iopub.status.idle":"2024-06-12T16:15:07.448057Z","shell.execute_reply.started":"2024-06-12T16:15:07.438732Z","shell.execute_reply":"2024-06-12T16:15:07.446747Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"for pred, true in zip(formatted_predictions, theoretical_answers):\n    print(\"ID:\", pred[\"id\"])\n    print(\"Predicted Answer:\", pred[\"prediction_text\"])\n    print(\"True Answer:\", true[\"answers\"])\n    print()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"theoretical_answers[2]\n     ","metadata":{"execution":{"iopub.status.busy":"2024-06-12T16:15:21.148146Z","iopub.execute_input":"2024-06-12T16:15:21.148557Z","iopub.status.idle":"2024-06-12T16:15:21.157925Z","shell.execute_reply.started":"2024-06-12T16:15:21.148523Z","shell.execute_reply":"2024-06-12T16:15:21.156842Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"{'id': 'bn_wiki_2812_03',\n 'answers': {'answer_start': [399, 399],\n  'text': ['ржжрзНржмрж╛ржжрж╢ рж╢рждрж╛ржмрзНржжрзАрждрзЗ', 'ржжрзНржмрж╛ржжрж╢ рж╢рждрж╛ржмрзНржжрзАрждрзЗ']}}"},"metadata":{}}]},{"cell_type":"markdown","source":"Then we can call compute on it. We just need to format predictions and labels a bit as it expects a list of dictionaries and not one big dictionary. In the case of squad_v2, we also have to set a `no_answer_probability` argument (which we set to 0.0 here as we have already set the answer to empty if we picked it).","metadata":{"id":"gi-AbCjpw2EC"}},{"cell_type":"code","source":"metric.compute(predictions=formatted_predictions, references=theoretical_answers)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T16:15:25.112291Z","iopub.execute_input":"2024-06-12T16:15:25.112646Z","iopub.status.idle":"2024-06-12T16:15:25.356598Z","shell.execute_reply.started":"2024-06-12T16:15:25.112617Z","shell.execute_reply":"2024-06-12T16:15:25.355495Z"},"trusted":true},"execution_count":44,"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"{'exact': 47.88494077834179,\n 'f1': 60.038975495562674,\n 'total': 1182,\n 'HasAns_exact': 64.97695852534562,\n 'HasAns_f1': 81.5277293038653,\n 'HasAns_total': 868,\n 'NoAns_exact': 0.6369426751592356,\n 'NoAns_f1': 0.6369426751592356,\n 'NoAns_total': 314,\n 'best_exact': 47.71573604060914,\n 'best_exact_thresh': 0.0,\n 'best_f1': 59.86977075782999,\n 'best_f1_thresh': 0.0}"},"metadata":{}}]},{"cell_type":"markdown","source":"You can now upload the result of the training to the Hub, just execute this instruction:","metadata":{"id":"pRhdqJq8w2EC"}},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"id":"23qNplt8w2EC","execution":{"iopub.status.busy":"2024-06-12T16:15:31.924985Z","iopub.execute_input":"2024-06-12T16:15:31.925437Z","iopub.status.idle":"2024-06-12T16:15:39.358506Z","shell.execute_reply.started":"2024-06-12T16:15:31.925405Z","shell.execute_reply":"2024-06-12T16:15:39.357394Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/AsifAbrar6/xlm-roberta-base-finetuned-RQA-confirmation/commit/a4cd0a2cd96e849689f808506a1ef2a604730880', commit_message='End of training', commit_description='', oid='a4cd0a2cd96e849689f808506a1ef2a604730880', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"markdown","source":"You can now share this model with all your friends, family, favorite pets: they can all load it with the identifier `\"your-username/the-name-you-picked\"` so for instance:\n\n```python\nfrom transformers import AutoModelForQuestionAnswering\n\nmodel = AutoModelForQuestionAnswering.from_pretrained(\"sgugger/my-awesome-model\")\n```","metadata":{"id":"7jVZosDPw2EC"}},{"cell_type":"code","source":"from transformers import AutoModelForQuestionAnswering\n\nmodel = AutoModelForQuestionAnswering.from_pretrained(\"AsifAbrar6/xlm-roberta-base-finetuned-RQA-confirmation\")","metadata":{"id":"9p-yLV09w2EC","execution":{"iopub.status.busy":"2024-06-12T16:17:44.358848Z","iopub.execute_input":"2024-06-12T16:17:44.359272Z","iopub.status.idle":"2024-06-12T16:18:06.349845Z","shell.execute_reply.started":"2024-06-12T16:17:44.359230Z","shell.execute_reply":"2024-06-12T16:18:06.348733Z"},"trusted":true},"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95eff9f4c7da478ebc3dc9594c7ff0d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5b904462b7d4e46bb6c8a77ba361e6d"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import pipeline, AutoModelForQuestionAnswering, AutoTokenizer\n\nmodel_name = \"AsifAbrar6/xlm-roberta-base-finetuned-RQA-confirmation\"\n\n# Load the model and tokenizer\nmodel = AutoModelForQuestionAnswering.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n\n# a) Get predictions\nnlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\nQA_input = {\n    'question': 'ржврж╛ржХрж╛ ржХрж┐ ржмрж╛ржВрж▓рж╛ржжрзЗрж╢рзЗрж░ рж░рж╛ржЬржзрж╛ржирзА?',\n    'context': 'рж╣рзНржпрж╛ржБ ржирж╛ ржмрж╛ржВрж▓рж╛ржжрзЗрж╢ ржжржХрзНрж╖рж┐ржг ржПрж╢рж┐ржпрж╝рж╛рж░ ржПржХржЯрж┐ ржЧрзБрж░рзБрждрзНржмржкрзВрж░рзНржг ржжрзЗрж╢ред ржПрж░ рж░рж╛ржЬржзрж╛ржирзА ржврж╛ржХрж╛, ржпрж╛ ржжрзЗрж╢ржЯрж┐рж░ ржмрзГрж╣рждрзНрждржо рж╢рж╣рж░ржУ ржмржЯрзЗред ржмрж╛ржВрж▓рж╛ржжрзЗрж╢ ржкрзНрж░ржХрзГрждрж┐рж░ рж╕рзМржирзНржжрж░рзНржпрзЗ ржнрж░ржкрзБрж░ред ржПржЦрж╛ржирзЗ рж░ржпрж╝рзЗржЫрзЗ рж╕рзБржирзНржжрж░ржмржи, ржпрж╛ ржкрзГржерж┐ржмрзАрж░ рж╕ржмржЪрзЗржпрж╝рзЗ ржмржбрж╝ ржорзНржпрж╛ржиржЧрзНрж░рзЛржн ржмржиред ржПржЫрж╛ржбрж╝рж╛ ржХржХрзНрж╕ржмрж╛ржЬрж╛рж░ рж╕ржорзБржжрзНрж░ рж╕рзИржХржд рж░ржпрж╝рзЗржЫрзЗ, ржпрж╛ ржкрзГржерж┐ржмрзАрж░ ржжрзАрж░рзНржШрждржо ржЕржЦржгрзНржбрж┐ржд ржмрж╛рж▓рзБржХрж╛ржоржпрж╝ рж╕ржорзБржжрзНрж░ рж╕рзИржХрждред ржмрж╛ржВрж▓рж╛ржжрзЗрж╢рзЗрж░ ржкрзНрж░ржзрж╛ржи ржиржжрзА ржкржжрзНржорж╛, ржорзЗржШржирж╛, ржПржмржВ ржпржорзБржирж╛ред ржжрзЗрж╢рзЗрж░ ржЕрж░рзНржержирзАрждрж┐ ржХрзГрж╖рж┐ржнрж┐рждрзНрждрж┐ржХ рж╣рж▓рзЗржУ рж╢рж┐рж▓рзНржк ржЦрж╛рждржУ ржзрзАрж░рзЗ ржзрзАрж░рзЗ ржмрж┐ржХрж╢рж┐ржд рж╣ржЪрзНржЫрзЗред ржмрж╛ржВрж▓рж╛ржжрзЗрж╢рзЗрж░ рж╕ржВрж╕рзНржХрзГрждрж┐, ржнрж╛рж╖рж╛, ржПржмржВ ржРрждрж┐рж╣рзНржп ржЕрждрзНржпржирзНржд рж╕ржорзГржжрзНржзред'\n}\nres = nlp(QA_input)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-12T16:30:03.519960Z","iopub.execute_input":"2024-06-12T16:30:03.520636Z","iopub.status.idle":"2024-06-12T16:30:06.407851Z","shell.execute_reply.started":"2024-06-12T16:30:03.520603Z","shell.execute_reply":"2024-06-12T16:30:06.406630Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"print(res)","metadata":{"execution":{"iopub.status.busy":"2024-06-12T16:30:07.535236Z","iopub.execute_input":"2024-06-12T16:30:07.535661Z","iopub.status.idle":"2024-06-12T16:30:07.543004Z","shell.execute_reply.started":"2024-06-12T16:30:07.535613Z","shell.execute_reply":"2024-06-12T16:30:07.541636Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"{'score': 0.42931875586509705, 'start': 0, 'end': 5, 'answer': 'рж╣рзНржпрж╛ржБ'}\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}